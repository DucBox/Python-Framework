{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EVlrG3ydWhWk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"concrete_data.csv\")"
      ],
      "metadata": {
        "id": "MtGk92yjWrsE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "pnl-IGItW98M",
        "outputId": "68266622-ccf7-4cc6-acbc-37cac78a72fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0   540.0                 0.0      0.0  162.0               2.5   \n",
              "1   540.0                 0.0      0.0  162.0               2.5   \n",
              "2   332.5               142.5      0.0  228.0               0.0   \n",
              "3   332.5               142.5      0.0  228.0               0.0   \n",
              "4   198.6               132.4      0.0  192.0               0.0   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0            1040.0           676.0   28     79.99  \n",
              "1            1055.0           676.0   28     61.89  \n",
              "2             932.0           594.0  270     40.27  \n",
              "3             932.0           594.0  365     41.05  \n",
              "4             978.4           825.5  360     44.30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26306c3a-4822-446a-bad6-97c5bd018284\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26306c3a-4822-446a-bad6-97c5bd018284')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26306c3a-4822-446a-bad6-97c5bd018284 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26306c3a-4822-446a-bad6-97c5bd018284');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15b60fb9-aac6-4929-b716-7115fc20f24f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15b60fb9-aac6-4929-b716-7115fc20f24f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15b60fb9-aac6-4929-b716-7115fc20f24f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481532,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810584,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268765,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503247,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.97384139248552,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672077,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240437,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912512,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize 'Cement' feature\n",
        "mean_Cement = df['Cement'].mean()\n",
        "std_Cement =df['Cement'].std()\n",
        "df['Cement'] = (df['Cement'] - mean_Cement) / std_Cement\n",
        "\n",
        "#Normalize 'Blast Furnace Slag'\n",
        "mean_BlastFurnaceSlag = df['Blast Furnace Slag'].mean()\n",
        "std_BlastFurnaceSlag =df['Blast Furnace Slag'].std()\n",
        "df['Blast Furnace Slag'] = (df['Blast Furnace Slag'] - mean_BlastFurnaceSlag) / std_BlastFurnaceSlag\n",
        "\n",
        "#Normalize Fly Ash\n",
        "mean_FlyAsh = df['Fly Ash'].mean()\n",
        "std_FlyAsh =df['Fly Ash'].std()\n",
        "df['Fly Ash'] = (df['Fly Ash'] - mean_FlyAsh) / std_FlyAsh\n",
        "\n",
        "#Normalize Water\n",
        "mean_Water = df['Water'].mean()\n",
        "std_Water =df['Water'].std()\n",
        "df['Water'] = (df['Water'] - mean_Water) / std_Water\n",
        "\n",
        "#Normalizie Superplasticizer\n",
        "mean_Superplasticizer = df['Superplasticizer'].mean()\n",
        "std_Superplasticizer =df['Superplasticizer'].std()\n",
        "df['Superplasticizer'] = (df['Superplasticizer'] - mean_Superplasticizer) / std_Superplasticizer\n",
        "\n",
        "#Normalizie Coarse Aggregate\n",
        "mean_CoarseAggregate = df['Coarse Aggregate'].mean()\n",
        "std_CoarseAggregate =df['Coarse Aggregate'].std()\n",
        "df['Coarse Aggregate'] = (df['Coarse Aggregate'] - mean_CoarseAggregate) / std_CoarseAggregate\n",
        "\n",
        "#Normalize Fine Aggregate\n",
        "mean_FineAggregate = df['Fine Aggregate'].mean()\n",
        "std_FineAggregate =df['Fine Aggregate'].std()\n",
        "df['Fine Aggregate'] = (df['Fine Aggregate'] - mean_FineAggregate) / std_FineAggregate\n",
        "\n",
        "#Normalize Age\n",
        "mean_Age = df['Age'].mean()\n",
        "std_Age =df['Age'].std()\n",
        "df['Age'] = (df['Age'] - mean_Age) / std_Age\n"
      ],
      "metadata": {
        "id": "7qFtuSCdW_7z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "X = df.drop('Strength', axis=1)  # all columns except 'Strength'\n",
        "# Target\n",
        "y = df['Strength']\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "metadata": {
        "id": "aQ9dzB7sWsbq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Dense(10, activation='relu', input_shape=(8,)))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sapLin3H_m8",
        "outputId": "a832e06e-8331-4fe3-a12f-09a4734406f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                90        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101 (404.00 Byte)\n",
            "Trainable params: 101 (404.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Vi58ZFIDNP",
        "outputId": "14df5339-e831-45a5-aef7-1f674d01e8bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 19ms/step - loss: 1612.7603 - val_loss: 1507.1677\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1596.8627 - val_loss: 1492.6406\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1581.1368 - val_loss: 1478.1437\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1565.2740 - val_loss: 1463.4739\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1548.7761 - val_loss: 1448.2366\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1531.5657 - val_loss: 1432.0099\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1513.5709 - val_loss: 1414.8615\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1494.0880 - val_loss: 1397.3818\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1473.8126 - val_loss: 1378.5179\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1451.9984 - val_loss: 1358.9192\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1429.0576 - val_loss: 1338.2850\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1405.1901 - val_loss: 1316.1581\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1379.8270 - val_loss: 1293.5795\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1353.3524 - val_loss: 1269.8557\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1325.4490 - val_loss: 1245.3005\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1296.5603 - val_loss: 1219.7167\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1266.0643 - val_loss: 1193.4473\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1234.8334 - val_loss: 1165.3940\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1202.1440 - val_loss: 1137.2472\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1168.7018 - val_loss: 1108.4800\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1134.5680 - val_loss: 1078.6698\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1099.3246 - val_loss: 1048.6754\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1063.8353 - val_loss: 1018.2036\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1028.0870 - val_loss: 986.7278\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 991.3752 - val_loss: 955.6879\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 955.2700 - val_loss: 924.3315\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 918.9249 - val_loss: 893.4627\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 883.1727 - val_loss: 862.6980\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 847.3472 - val_loss: 832.5761\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 812.6576 - val_loss: 801.9491\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 778.0807 - val_loss: 772.4995\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 744.8754 - val_loss: 743.5228\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 712.3519 - val_loss: 714.7801\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 680.4812 - val_loss: 687.6312\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 650.2635 - val_loss: 660.7401\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 620.9250 - val_loss: 634.8503\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 593.1342 - val_loss: 609.6366\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 566.2021 - val_loss: 585.8472\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 541.0006 - val_loss: 562.5573\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 516.9039 - val_loss: 540.4644\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 494.1641 - val_loss: 519.3834\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 472.6762 - val_loss: 499.3039\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 452.7784 - val_loss: 479.9667\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 433.6743 - val_loss: 462.0457\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 416.2041 - val_loss: 444.6232\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 399.6631 - val_loss: 428.5977\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 384.7932 - val_loss: 412.9833\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 370.4713 - val_loss: 398.6019\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 357.4918 - val_loss: 385.0952\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 345.3052 - val_loss: 372.6688\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 334.3429 - val_loss: 360.4067\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 324.2128 - val_loss: 348.7569\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 314.3775 - val_loss: 338.7027\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 305.8848 - val_loss: 328.6299\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 297.7728 - val_loss: 319.3415\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 290.3522 - val_loss: 310.5192\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 283.1670 - val_loss: 302.4016\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 276.6635 - val_loss: 294.7928\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 270.6211 - val_loss: 287.1175\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 264.7984 - val_loss: 280.3004\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 259.5451 - val_loss: 273.9413\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 254.6872 - val_loss: 267.5804\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 249.9271 - val_loss: 261.8502\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 245.5473 - val_loss: 256.6143\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 241.5599 - val_loss: 251.1554\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 237.4230 - val_loss: 246.3817\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 233.6244 - val_loss: 241.6339\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 229.9148 - val_loss: 237.0720\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 226.4054 - val_loss: 232.9119\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 223.0653 - val_loss: 228.6596\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 219.7776 - val_loss: 224.7649\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 216.6492 - val_loss: 221.1691\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 213.5648 - val_loss: 217.7833\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 210.7291 - val_loss: 214.3228\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 207.9310 - val_loss: 211.1646\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 205.2481 - val_loss: 208.2373\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 202.6469 - val_loss: 205.3020\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 200.2329 - val_loss: 202.4931\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 197.8108 - val_loss: 199.7470\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 195.4847 - val_loss: 197.4172\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 193.3816 - val_loss: 194.9055\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 191.1892 - val_loss: 192.5560\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 189.0752 - val_loss: 190.3218\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 187.0981 - val_loss: 188.1050\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 185.0758 - val_loss: 185.8912\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 183.1528 - val_loss: 184.0516\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 181.3594 - val_loss: 182.1533\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 179.6101 - val_loss: 180.2186\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 177.7947 - val_loss: 178.4106\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 176.1453 - val_loss: 176.7900\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 174.6055 - val_loss: 175.1215\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 173.0072 - val_loss: 173.5829\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 171.4654 - val_loss: 172.0215\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 169.9551 - val_loss: 170.3572\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 168.3670 - val_loss: 168.9129\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 166.9113 - val_loss: 167.4434\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 165.4870 - val_loss: 165.9541\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 163.9834 - val_loss: 164.5983\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 162.6413 - val_loss: 163.1974\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 161.1480 - val_loss: 161.8371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction = model.predict(X_test).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gahkXUdWIErD",
        "outputId": "922d5d72-f6df-4c9e-9adc-f2c0a9e4a626"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_prediction)\n",
        "print(f\"The Mean Squared Error (MSE) on the Test set is: {mse:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IBDIcIvILDx",
        "outputId": "06712974-5fbc-43c2-c89a-f3e5074d37f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error (MSE) on the Test set is: 161.837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "for i in range(51):\n",
        "  X = df.drop('Strength', axis=1)\n",
        "  y = df['Strength']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(8,)))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test, y_test))\n",
        "  y_prediction = model.predict(X_test).flatten()\n",
        "  mse = mean_squared_error(y_test, y_prediction)\n",
        "  print(f\"The Mean Squared Error (MSE) on the Test set is: {mse:.3f}\")\n",
        "  mse_list.append(mse)\n",
        "print(mse_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VflCqevIL9E",
        "outputId": "95f9a3ed-7dcd-40dd-b310-a8f3ebb46305"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 904.7866 - val_loss: 823.1396\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 872.3478 - val_loss: 791.5626\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 839.8488 - val_loss: 759.8509\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 807.0647 - val_loss: 728.5037\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 774.8091 - val_loss: 697.4752\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 742.6728 - val_loss: 666.4487\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 710.8573 - val_loss: 636.3587\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 680.0272 - val_loss: 606.0173\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 649.3450 - val_loss: 577.4758\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 620.0698 - val_loss: 549.2520\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 591.4432 - val_loss: 522.4374\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 563.7023 - val_loss: 496.4305\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 537.1076 - val_loss: 471.8254\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 512.0272 - val_loss: 447.3329\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 487.2974 - val_loss: 425.3049\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 464.7323 - val_loss: 403.9017\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 443.2409 - val_loss: 383.5957\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 422.6178 - val_loss: 365.3946\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 403.5857 - val_loss: 347.9482\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 385.4819 - val_loss: 332.3137\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 369.2368 - val_loss: 317.0956\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 353.6719 - val_loss: 303.3189\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 339.4211 - val_loss: 290.8188\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 326.2681 - val_loss: 279.2695\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 313.9931 - val_loss: 268.5488\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 302.6962 - val_loss: 259.1886\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 292.5264 - val_loss: 250.3044\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 283.1983 - val_loss: 242.4678\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 274.4449 - val_loss: 235.5977\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 266.8987 - val_loss: 229.0556\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 259.5489 - val_loss: 223.5702\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 253.1984 - val_loss: 218.3166\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 247.1445 - val_loss: 213.7906\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 241.7771 - val_loss: 209.4595\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 236.7186 - val_loss: 205.6187\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 232.0971 - val_loss: 202.1269\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 227.8004 - val_loss: 199.0970\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 223.8833 - val_loss: 196.2126\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.2766 - val_loss: 193.4710\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 216.7713 - val_loss: 191.1615\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 213.5065 - val_loss: 188.9816\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.4683 - val_loss: 186.8735\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 207.6747 - val_loss: 184.7253\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.7175 - val_loss: 182.8189\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.1830 - val_loss: 180.9203\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 199.5485 - val_loss: 179.2546\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.2871 - val_loss: 177.5154\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 194.9747 - val_loss: 175.9225\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.7688 - val_loss: 174.4314\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 190.6440 - val_loss: 172.9156\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 188.7005 - val_loss: 171.4541\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.7969 - val_loss: 170.1225\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.8897 - val_loss: 168.6884\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 183.1857 - val_loss: 167.4711\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 181.4071 - val_loss: 166.2291\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 179.6953 - val_loss: 165.0509\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 178.0680 - val_loss: 163.9156\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.5155 - val_loss: 162.7551\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 174.9507 - val_loss: 161.5873\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 173.5007 - val_loss: 160.6864\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 171.9482 - val_loss: 159.5454\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 170.5093 - val_loss: 158.5146\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 169.0970 - val_loss: 157.5258\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 167.7259 - val_loss: 156.5403\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 166.4042 - val_loss: 155.5721\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 165.0701 - val_loss: 154.5394\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 163.7431 - val_loss: 153.6770\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.4483 - val_loss: 152.7684\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 161.2732 - val_loss: 151.8757\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 159.9312 - val_loss: 150.9398\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 158.8356 - val_loss: 150.0109\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 157.6811 - val_loss: 149.3235\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 156.5884 - val_loss: 148.4415\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 155.4779 - val_loss: 147.7708\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 154.5092 - val_loss: 146.9406\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 146.941\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1476.8379 - val_loss: 1594.7623\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1458.1064 - val_loss: 1574.1328\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1438.8568 - val_loss: 1552.6949\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1418.8691 - val_loss: 1530.8123\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1398.1736 - val_loss: 1507.8304\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1376.5067 - val_loss: 1483.8073\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1354.1727 - val_loss: 1458.6608\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1331.1605 - val_loss: 1432.5594\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1306.6461 - val_loss: 1406.2799\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1281.7695 - val_loss: 1378.4796\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1255.7062 - val_loss: 1349.6588\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1228.9857 - val_loss: 1319.7841\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1200.9520 - val_loss: 1289.4402\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1172.5491 - val_loss: 1257.6387\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1143.0767 - val_loss: 1225.4061\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1113.0717 - val_loss: 1192.3057\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1082.3280 - val_loss: 1158.6338\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1051.1224 - val_loss: 1124.8004\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1019.6444 - val_loss: 1090.1890\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 987.4902 - val_loss: 1055.6335\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 955.3686 - val_loss: 1020.7361\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 923.1624 - val_loss: 985.3524\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 890.5800 - val_loss: 951.1272\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 858.4509 - val_loss: 916.7652\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 826.5598 - val_loss: 881.8962\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 794.3938 - val_loss: 848.4561\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 763.1378 - val_loss: 815.3220\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 732.0093 - val_loss: 782.6042\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 701.3552 - val_loss: 750.7020\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 671.6370 - val_loss: 719.2559\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 641.8629 - val_loss: 689.2786\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 613.3604 - val_loss: 659.8629\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 585.8494 - val_loss: 631.2179\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 558.9433 - val_loss: 603.6010\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 532.7975 - val_loss: 577.6232\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 507.8801 - val_loss: 552.5361\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 484.0817 - val_loss: 528.3714\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 461.1235 - val_loss: 505.6079\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 439.2385 - val_loss: 484.0659\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 418.5122 - val_loss: 463.5938\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 398.7350 - val_loss: 444.6406\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 380.2148 - val_loss: 426.7826\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 362.9972 - val_loss: 409.8264\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 346.4718 - val_loss: 394.2541\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 331.0101 - val_loss: 379.9936\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 316.8031 - val_loss: 366.2545\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 303.3425 - val_loss: 353.7375\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 291.0414 - val_loss: 342.1791\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 279.6606 - val_loss: 331.6646\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 269.0416 - val_loss: 322.3217\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 259.5549 - val_loss: 313.2629\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 250.4093 - val_loss: 305.1106\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 242.2057 - val_loss: 297.4169\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.5497 - val_loss: 290.5591\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 227.5454 - val_loss: 284.1199\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 221.1809 - val_loss: 278.4055\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 215.2614 - val_loss: 273.2556\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 210.0359 - val_loss: 268.2786\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 205.1327 - val_loss: 263.5781\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 200.5078 - val_loss: 259.3697\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 196.3593 - val_loss: 255.4559\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 192.5837 - val_loss: 251.7726\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 188.9843 - val_loss: 248.3961\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 185.8277 - val_loss: 244.9422\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 182.7171 - val_loss: 242.0313\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 180.0114 - val_loss: 239.2236\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 177.4053 - val_loss: 236.5826\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 175.0113 - val_loss: 234.0323\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 172.7927 - val_loss: 231.4913\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.8592 - val_loss: 229.3117\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 168.7906 - val_loss: 227.0318\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 167.0143 - val_loss: 224.9932\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 165.3120 - val_loss: 222.8975\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 163.6570 - val_loss: 220.6977\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.0984 - val_loss: 218.7990\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 160.6457 - val_loss: 216.8104\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 159.2352 - val_loss: 215.2372\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 157.9214 - val_loss: 213.3467\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 156.6279 - val_loss: 211.8918\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 155.5032 - val_loss: 210.2245\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 154.2686 - val_loss: 208.4277\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 153.1236 - val_loss: 206.7972\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 151.9610 - val_loss: 205.1391\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 150.9268 - val_loss: 203.4179\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 149.8704 - val_loss: 202.0139\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 148.9636 - val_loss: 200.7092\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 147.9851 - val_loss: 199.1895\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 147.1277 - val_loss: 197.6335\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 146.3005 - val_loss: 196.1608\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 145.4327 - val_loss: 194.7362\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 144.6910 - val_loss: 193.5171\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 143.9440 - val_loss: 192.3484\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 143.2327 - val_loss: 191.2495\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 142.5964 - val_loss: 190.4578\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 141.9240 - val_loss: 189.1877\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 141.3419 - val_loss: 188.1588\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 140.7428 - val_loss: 187.2776\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 140.1932 - val_loss: 186.2440\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 139.6353 - val_loss: 185.0888\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 139.0873 - val_loss: 184.2429\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 184.243\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 1517.1832 - val_loss: 1510.0919\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1501.9102 - val_loss: 1494.4912\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1486.0524 - val_loss: 1478.1826\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1469.3444 - val_loss: 1460.6230\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1451.3903 - val_loss: 1441.6910\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1432.0836 - val_loss: 1421.5756\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1411.3456 - val_loss: 1400.1328\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1389.2201 - val_loss: 1377.2736\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1365.6536 - val_loss: 1352.8541\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1340.3981 - val_loss: 1326.6113\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1313.7815 - val_loss: 1298.4834\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1285.0444 - val_loss: 1269.3446\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1254.9259 - val_loss: 1238.7288\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1223.4431 - val_loss: 1206.4502\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1190.3307 - val_loss: 1172.6899\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1156.5759 - val_loss: 1136.9850\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1121.0774 - val_loss: 1100.8723\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1084.1754 - val_loss: 1064.1427\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1047.3245 - val_loss: 1025.8348\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1008.8972 - val_loss: 987.9344\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 970.4354 - val_loss: 949.6502\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 932.2126 - val_loss: 909.9637\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 893.0349 - val_loss: 871.5895\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 854.9962 - val_loss: 832.7213\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 816.9731 - val_loss: 795.4908\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 780.3317 - val_loss: 758.1982\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 743.7550 - val_loss: 722.1201\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 708.8270 - val_loss: 686.1130\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 674.2308 - val_loss: 652.6100\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 641.5031 - val_loss: 620.6207\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 610.8329 - val_loss: 588.8729\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 580.2704 - val_loss: 559.5835\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 552.0319 - val_loss: 531.2897\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 524.7959 - val_loss: 504.5239\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 499.0276 - val_loss: 479.1967\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 475.2405 - val_loss: 455.4912\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 452.8714 - val_loss: 433.2757\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 431.6241 - val_loss: 412.9745\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 412.3916 - val_loss: 393.6108\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 393.7654 - val_loss: 376.5541\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 377.2500 - val_loss: 359.6469\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 361.4528 - val_loss: 344.1675\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 346.8467 - val_loss: 330.2270\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 333.5321 - val_loss: 317.5879\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 320.9699 - val_loss: 305.5127\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 309.7884 - val_loss: 294.4697\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 299.1705 - val_loss: 285.0464\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 289.9944 - val_loss: 275.3712\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 280.8088 - val_loss: 267.4261\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 272.8222 - val_loss: 259.8661\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 265.4537 - val_loss: 252.6353\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 258.7101 - val_loss: 246.2157\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 252.3530 - val_loss: 240.4603\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 246.4359 - val_loss: 235.0912\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 241.3020 - val_loss: 229.7701\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 236.2394 - val_loss: 225.1245\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 231.6988 - val_loss: 220.6150\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 227.3649 - val_loss: 216.4772\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 223.3258 - val_loss: 212.5584\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 219.6848 - val_loss: 209.0262\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 216.1344 - val_loss: 205.7992\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 212.8796 - val_loss: 202.5363\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 209.7499 - val_loss: 199.6501\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 206.8264 - val_loss: 196.9386\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.1617 - val_loss: 194.4953\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.4234 - val_loss: 192.0268\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 199.0759 - val_loss: 189.6219\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 196.6791 - val_loss: 187.0614\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 194.3351 - val_loss: 185.0367\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 192.1922 - val_loss: 183.0003\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 190.1372 - val_loss: 181.1049\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 188.1979 - val_loss: 179.3155\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 186.2526 - val_loss: 177.3081\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.3087 - val_loss: 175.6121\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 182.5744 - val_loss: 173.7700\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 180.7243 - val_loss: 172.3457\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 179.0769 - val_loss: 170.6116\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 177.3839 - val_loss: 169.0165\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 175.7950 - val_loss: 167.7802\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 174.2653 - val_loss: 166.4272\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 172.6860 - val_loss: 164.9470\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 171.2681 - val_loss: 163.5478\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 169.8369 - val_loss: 162.0049\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.3738 - val_loss: 160.8203\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.0352 - val_loss: 159.6206\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 165.6591 - val_loss: 158.2376\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 164.3656 - val_loss: 156.9866\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 163.2004 - val_loss: 155.6980\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 161.7328 - val_loss: 154.8595\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 160.5167 - val_loss: 153.4608\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 159.2193 - val_loss: 152.4610\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 158.1241 - val_loss: 151.2943\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 156.9400 - val_loss: 150.3472\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 155.8680 - val_loss: 148.8242\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 154.6010 - val_loss: 148.0166\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 153.5742 - val_loss: 146.9000\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 152.5216 - val_loss: 145.8634\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 151.5099 - val_loss: 144.8312\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 150.4669 - val_loss: 143.7709\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 149.5298 - val_loss: 143.0981\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 143.098\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1576.6414 - val_loss: 1568.8906\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1560.5884 - val_loss: 1552.7673\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1545.2346 - val_loss: 1537.4487\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1530.4966 - val_loss: 1522.2039\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1515.8610 - val_loss: 1507.3892\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1501.4517 - val_loss: 1492.2681\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1486.6799 - val_loss: 1477.6083\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1472.2029 - val_loss: 1462.2549\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1457.1212 - val_loss: 1446.7122\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1441.9071 - val_loss: 1430.6385\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1426.1006 - val_loss: 1414.0577\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1409.8479 - val_loss: 1396.9926\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1393.0267 - val_loss: 1379.3381\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1375.5885 - val_loss: 1361.2343\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1357.4556 - val_loss: 1342.3077\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1338.6593 - val_loss: 1322.3046\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1318.9015 - val_loss: 1301.5933\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1298.3083 - val_loss: 1280.1606\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1277.2062 - val_loss: 1257.6395\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1254.8878 - val_loss: 1234.7220\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1231.9131 - val_loss: 1210.2675\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1207.9154 - val_loss: 1184.9585\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1182.9708 - val_loss: 1158.9204\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1157.2570 - val_loss: 1131.3788\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1130.2429 - val_loss: 1103.4030\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1102.4038 - val_loss: 1074.6666\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1073.9280 - val_loss: 1044.4459\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1044.3357 - val_loss: 1014.0528\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1014.2294 - val_loss: 982.6146\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 983.0145 - val_loss: 950.7302\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 951.6149 - val_loss: 918.2706\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 919.4666 - val_loss: 884.8618\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 887.0118 - val_loss: 850.6478\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 854.3209 - val_loss: 817.3326\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 821.5590 - val_loss: 784.7798\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 789.5204 - val_loss: 751.7330\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 757.6168 - val_loss: 718.9567\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 725.6226 - val_loss: 687.3793\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 694.7856 - val_loss: 656.1948\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 664.3564 - val_loss: 626.0026\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 634.9468 - val_loss: 596.8803\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 606.6458 - val_loss: 568.7080\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 579.3735 - val_loss: 541.3050\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 552.8443 - val_loss: 515.3094\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 527.4462 - val_loss: 490.7622\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 503.2636 - val_loss: 467.0693\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 480.1832 - val_loss: 444.7332\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 458.0945 - val_loss: 423.7026\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 437.6258 - val_loss: 403.1457\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 417.4571 - val_loss: 384.3792\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 399.2653 - val_loss: 365.8621\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 381.2545 - val_loss: 349.1921\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 364.7079 - val_loss: 333.5634\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 349.0520 - val_loss: 318.8064\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 334.8098 - val_loss: 304.4199\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 320.8361 - val_loss: 291.9654\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 308.5564 - val_loss: 279.9846\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 296.7687 - val_loss: 269.0846\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 286.0890 - val_loss: 258.9719\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 276.2263 - val_loss: 249.6299\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 266.8361 - val_loss: 241.1494\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 258.5282 - val_loss: 233.4113\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 250.8003 - val_loss: 226.2548\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 243.6572 - val_loss: 219.7522\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 237.1102 - val_loss: 213.7016\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 231.1413 - val_loss: 208.3987\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 225.7620 - val_loss: 203.3457\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 220.8016 - val_loss: 199.0120\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 216.3461 - val_loss: 194.9552\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 212.1329 - val_loss: 191.2811\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 208.4184 - val_loss: 187.7518\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.7288 - val_loss: 184.7349\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 201.5892 - val_loss: 181.8687\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 198.5947 - val_loss: 179.2243\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 195.8787 - val_loss: 176.7000\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 193.2616 - val_loss: 174.4987\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 190.8868 - val_loss: 172.6085\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 188.7221 - val_loss: 170.6220\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 186.6937 - val_loss: 168.8387\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 184.6722 - val_loss: 167.2881\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 182.7274 - val_loss: 165.7395\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 181.0284 - val_loss: 164.4186\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 179.3938 - val_loss: 163.1782\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 177.9919 - val_loss: 161.9622\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.4583 - val_loss: 160.9016\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.1876 - val_loss: 159.7797\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 173.8439 - val_loss: 158.7340\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 172.7198 - val_loss: 157.7650\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.4710 - val_loss: 156.8397\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.3272 - val_loss: 155.8879\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 169.2853 - val_loss: 154.9742\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.2005 - val_loss: 154.0285\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.1617 - val_loss: 153.1839\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 166.1842 - val_loss: 152.3629\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 165.2825 - val_loss: 151.5413\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 164.1766 - val_loss: 150.6852\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 163.2635 - val_loss: 149.8851\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.2886 - val_loss: 149.1104\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 161.4189 - val_loss: 148.4423\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 160.5856 - val_loss: 147.6112\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 147.611\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 1673.1849 - val_loss: 1503.7126\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1655.2529 - val_loss: 1487.7192\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1638.5247 - val_loss: 1473.1742\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1623.0850 - val_loss: 1459.3708\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1608.5466 - val_loss: 1446.1445\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1594.5653 - val_loss: 1433.7375\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1581.2850 - val_loss: 1421.4912\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1568.2010 - val_loss: 1409.9344\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1555.5848 - val_loss: 1398.4113\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1543.1292 - val_loss: 1386.8069\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1530.6226 - val_loss: 1375.3538\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1518.2119 - val_loss: 1363.8101\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1505.6477 - val_loss: 1352.1019\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1492.7887 - val_loss: 1340.4041\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1479.9359 - val_loss: 1328.0186\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1466.6027 - val_loss: 1315.3934\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1452.8569 - val_loss: 1302.5887\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1438.6930 - val_loss: 1289.2378\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1423.9375 - val_loss: 1275.3712\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1408.6628 - val_loss: 1260.8997\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1392.5750 - val_loss: 1245.9833\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1375.7957 - val_loss: 1230.3912\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1358.2020 - val_loss: 1213.7235\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1339.5354 - val_loss: 1196.2755\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1319.6957 - val_loss: 1177.6705\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1298.7103 - val_loss: 1158.4158\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1276.7760 - val_loss: 1137.9557\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1253.6742 - val_loss: 1116.5909\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1229.4362 - val_loss: 1094.6863\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1204.6270 - val_loss: 1071.2947\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1178.2754 - val_loss: 1047.9385\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1151.6458 - val_loss: 1023.5740\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1124.3850 - val_loss: 997.5291\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1095.3566 - val_loss: 971.0408\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1065.4045 - val_loss: 944.0927\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1034.9366 - val_loss: 915.8194\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1003.4326 - val_loss: 886.9664\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 971.2286 - val_loss: 857.7321\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 938.6450 - val_loss: 827.8112\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 905.4779 - val_loss: 797.7170\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 872.4259 - val_loss: 767.4483\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 839.4068 - val_loss: 737.5782\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 806.9092 - val_loss: 708.2489\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 774.4123 - val_loss: 680.1185\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 743.2740 - val_loss: 651.6516\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 712.2229 - val_loss: 624.8953\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 682.7332 - val_loss: 598.0861\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 653.4585 - val_loss: 572.8901\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 625.7054 - val_loss: 548.3477\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 598.9688 - val_loss: 524.3705\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 572.7945 - val_loss: 501.7383\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 548.3496 - val_loss: 480.1776\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 524.7933 - val_loss: 459.7924\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 502.4628 - val_loss: 440.3167\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 481.0767 - val_loss: 422.5497\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 461.1631 - val_loss: 405.3850\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 442.3259 - val_loss: 389.1873\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 424.3729 - val_loss: 374.0503\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 407.4637 - val_loss: 360.1376\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 392.0450 - val_loss: 346.4888\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 377.0927 - val_loss: 334.2935\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 363.3996 - val_loss: 322.9125\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 350.7264 - val_loss: 311.9444\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 338.7280 - val_loss: 301.9380\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 327.5352 - val_loss: 292.8885\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 317.2637 - val_loss: 284.2738\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 307.6822 - val_loss: 276.5074\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 298.8577 - val_loss: 269.1107\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 290.6645 - val_loss: 262.2581\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 282.9416 - val_loss: 256.1052\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 275.8540 - val_loss: 250.2249\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 269.2450 - val_loss: 244.7516\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 263.1422 - val_loss: 239.6382\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 257.5156 - val_loss: 235.1074\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 252.1059 - val_loss: 230.8042\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 247.2280 - val_loss: 226.6475\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 242.6250 - val_loss: 222.8111\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 238.2471 - val_loss: 219.1160\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.1185 - val_loss: 215.5322\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 230.2493 - val_loss: 212.2699\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 226.7116 - val_loss: 209.1763\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.4372 - val_loss: 206.0952\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.1784 - val_loss: 203.3384\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 217.2025 - val_loss: 200.5923\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.2130 - val_loss: 198.1388\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 211.5381 - val_loss: 195.5597\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 208.9491 - val_loss: 193.2696\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 206.4268 - val_loss: 191.0583\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.0795 - val_loss: 188.9141\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.8996 - val_loss: 186.7846\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 199.8522 - val_loss: 184.7063\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.8999 - val_loss: 182.7110\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 195.9192 - val_loss: 180.8811\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 194.1687 - val_loss: 178.9761\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.3316 - val_loss: 177.4952\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 190.8199 - val_loss: 175.6802\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.0690 - val_loss: 174.1093\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 187.5895 - val_loss: 172.5490\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 186.0863 - val_loss: 171.0271\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.6064 - val_loss: 169.4702\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 169.470\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 9ms/step - loss: 1506.6057 - val_loss: 1541.0652\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1489.0569 - val_loss: 1523.2758\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1470.6959 - val_loss: 1504.1937\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1450.8188 - val_loss: 1484.0150\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1429.9948 - val_loss: 1461.7281\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1407.4939 - val_loss: 1438.3621\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1383.3796 - val_loss: 1413.7198\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1358.5085 - val_loss: 1386.8947\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1331.8099 - val_loss: 1359.7032\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1304.2876 - val_loss: 1331.0439\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1275.3737 - val_loss: 1301.3381\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1245.6444 - val_loss: 1269.9131\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1214.1218 - val_loss: 1237.7942\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1181.9115 - val_loss: 1204.4585\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1148.7974 - val_loss: 1170.1033\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1114.6084 - val_loss: 1134.9901\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1080.2007 - val_loss: 1098.8799\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1044.7385 - val_loss: 1063.4696\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1009.8257 - val_loss: 1026.6847\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 974.0901 - val_loss: 990.2386\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 938.4193 - val_loss: 953.9700\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 903.2063 - val_loss: 917.4291\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 867.4000 - val_loss: 882.0202\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 833.1921 - val_loss: 846.1826\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 798.4924 - val_loss: 811.8434\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 764.8719 - val_loss: 777.8295\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 731.9926 - val_loss: 743.8467\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 699.2360 - val_loss: 711.4297\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 668.0681 - val_loss: 679.7343\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 637.6536 - val_loss: 648.9526\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 608.3334 - val_loss: 619.4212\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 579.8372 - val_loss: 591.8419\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 553.2283 - val_loss: 564.4996\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 527.1227 - val_loss: 538.5806\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 502.2521 - val_loss: 514.5353\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 479.0912 - val_loss: 490.7673\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 456.4496 - val_loss: 468.6720\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 435.5452 - val_loss: 447.4712\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 415.3736 - val_loss: 428.0782\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 396.5595 - val_loss: 410.0959\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 379.1100 - val_loss: 392.5546\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 362.4800 - val_loss: 376.6927\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 347.1348 - val_loss: 361.6215\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 332.6213 - val_loss: 348.0571\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 319.4088 - val_loss: 335.2319\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 307.0349 - val_loss: 323.2928\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 295.3604 - val_loss: 312.5186\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 284.7332 - val_loss: 302.2871\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 274.9185 - val_loss: 292.8028\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 265.6679 - val_loss: 284.2729\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 257.3334 - val_loss: 276.0650\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 249.4769 - val_loss: 269.0349\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 242.2940 - val_loss: 262.4195\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 235.8217 - val_loss: 255.9346\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 229.5235 - val_loss: 250.2625\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 223.8390 - val_loss: 245.2009\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 218.9790 - val_loss: 240.0736\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 213.9364 - val_loss: 235.8179\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 209.4805 - val_loss: 232.0236\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 205.3708 - val_loss: 228.0799\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.4964 - val_loss: 224.7713\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 197.9384 - val_loss: 221.5578\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 194.6104 - val_loss: 218.5691\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 191.5680 - val_loss: 215.6677\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 188.5818 - val_loss: 213.2237\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 185.8726 - val_loss: 210.7496\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 183.4866 - val_loss: 208.5541\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 180.9941 - val_loss: 206.3314\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 178.7243 - val_loss: 204.3298\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 176.6620 - val_loss: 202.3710\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 174.6094 - val_loss: 200.6759\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 172.7541 - val_loss: 199.0811\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.9798 - val_loss: 197.6473\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 169.4251 - val_loss: 196.1336\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 167.7874 - val_loss: 194.4959\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 166.1929 - val_loss: 193.1213\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 164.8601 - val_loss: 191.6503\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 163.3198 - val_loss: 190.5493\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 161.9866 - val_loss: 189.2699\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 160.6149 - val_loss: 187.9033\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 159.2711 - val_loss: 186.7953\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 158.0786 - val_loss: 185.6285\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 156.8761 - val_loss: 184.4782\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 155.7390 - val_loss: 183.4405\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 154.5577 - val_loss: 182.2158\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 153.4314 - val_loss: 181.2890\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 152.3760 - val_loss: 180.0778\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 151.2461 - val_loss: 179.1962\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 150.1334 - val_loss: 178.1485\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 149.1265 - val_loss: 177.0461\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 148.0689 - val_loss: 176.0767\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 147.0244 - val_loss: 175.0177\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 145.9697 - val_loss: 174.0245\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 144.9372 - val_loss: 173.0621\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 144.0197 - val_loss: 172.0553\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 142.9681 - val_loss: 170.9727\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 141.9899 - val_loss: 169.9068\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 141.0321 - val_loss: 169.0015\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 140.0409 - val_loss: 168.0448\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 139.1325 - val_loss: 166.9701\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 166.970\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 13ms/step - loss: 1559.3416 - val_loss: 1408.8895\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1543.6720 - val_loss: 1394.5942\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1527.5759 - val_loss: 1380.0427\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1511.1938 - val_loss: 1364.4899\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1493.6718 - val_loss: 1348.3291\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1475.2817 - val_loss: 1331.2494\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1455.6534 - val_loss: 1312.8357\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1434.6125 - val_loss: 1293.3159\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1412.1018 - val_loss: 1272.2594\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1388.0723 - val_loss: 1249.5979\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1361.6304 - val_loss: 1225.9377\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1333.7053 - val_loss: 1200.2296\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1304.1183 - val_loss: 1172.3864\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1272.1210 - val_loss: 1143.5072\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1238.4479 - val_loss: 1113.6599\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1203.8994 - val_loss: 1081.6949\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1167.5161 - val_loss: 1049.0383\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1130.2634 - val_loss: 1015.5827\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1091.9739 - val_loss: 981.2294\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1052.9760 - val_loss: 945.8034\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1013.2294 - val_loss: 910.4792\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 972.8679 - val_loss: 875.3088\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 932.7659 - val_loss: 839.5322\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 892.3035 - val_loss: 804.1450\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 852.5233 - val_loss: 768.2944\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 812.6926 - val_loss: 733.2667\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 773.4000 - val_loss: 698.9846\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 735.0880 - val_loss: 664.9773\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 697.2701 - val_loss: 632.4883\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 660.8685 - val_loss: 600.2861\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 625.5820 - val_loss: 569.9745\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 591.8761 - val_loss: 540.5695\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 559.2894 - val_loss: 513.2413\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 528.9920 - val_loss: 486.5696\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 500.0401 - val_loss: 461.4393\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 473.2361 - val_loss: 438.2115\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 447.7513 - val_loss: 417.2611\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 424.7815 - val_loss: 397.2250\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 403.1533 - val_loss: 378.8406\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 383.0962 - val_loss: 362.3713\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 364.9083 - val_loss: 346.9586\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 348.3659 - val_loss: 332.8490\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 333.1107 - val_loss: 320.4221\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 319.4014 - val_loss: 309.0115\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 306.8844 - val_loss: 298.4437\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 295.2923 - val_loss: 289.0573\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 284.8812 - val_loss: 280.7424\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 275.4593 - val_loss: 272.8986\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.8372 - val_loss: 266.0728\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 259.0959 - val_loss: 259.8898\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 251.9986 - val_loss: 254.2410\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 245.7973 - val_loss: 248.9062\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 239.8355 - val_loss: 244.6937\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.6985 - val_loss: 240.3260\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.8033 - val_loss: 236.5322\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 225.5796 - val_loss: 232.7581\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 221.2328 - val_loss: 229.7682\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 217.5477 - val_loss: 226.7847\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.0100 - val_loss: 224.0160\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.7884 - val_loss: 221.3409\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 207.6978 - val_loss: 218.7594\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.6942 - val_loss: 216.5037\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 201.9402 - val_loss: 214.2693\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 199.2821 - val_loss: 212.1638\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 196.8152 - val_loss: 209.9995\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 194.4106 - val_loss: 208.0475\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.1208 - val_loss: 206.2278\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.9967 - val_loss: 204.3381\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 188.0344 - val_loss: 202.5888\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 185.8468 - val_loss: 200.9651\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.0309 - val_loss: 199.2737\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 182.1293 - val_loss: 197.6894\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 180.3625 - val_loss: 196.0838\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 178.6714 - val_loss: 194.5100\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 177.0853 - val_loss: 193.0929\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 175.5236 - val_loss: 191.6107\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 173.9873 - val_loss: 190.0966\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 172.5381 - val_loss: 188.7491\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.0480 - val_loss: 187.2948\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 169.6581 - val_loss: 185.8221\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 168.3866 - val_loss: 184.5789\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 166.9781 - val_loss: 183.2206\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.8361 - val_loss: 182.0376\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 164.3408 - val_loss: 180.8719\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 163.2073 - val_loss: 179.7247\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 162.0101 - val_loss: 178.6262\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 160.9508 - val_loss: 177.6617\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 159.9018 - val_loss: 176.6941\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 158.9342 - val_loss: 175.6760\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 157.9384 - val_loss: 174.7316\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 156.9380 - val_loss: 173.7710\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 156.0222 - val_loss: 172.8288\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 155.1824 - val_loss: 171.7979\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 154.1880 - val_loss: 171.1151\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 153.3997 - val_loss: 170.1444\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 152.5275 - val_loss: 169.3848\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 151.6793 - val_loss: 168.5785\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 150.8552 - val_loss: 167.7386\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 150.1014 - val_loss: 167.0025\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 149.3507 - val_loss: 166.1823\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 166.182\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 16ms/step - loss: 1441.4554 - val_loss: 1542.5521\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1424.1943 - val_loss: 1525.5703\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1405.7406 - val_loss: 1507.2144\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1385.8256 - val_loss: 1487.2667\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1364.3279 - val_loss: 1465.6768\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1341.0997 - val_loss: 1442.7875\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1316.7358 - val_loss: 1417.8960\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1290.0640 - val_loss: 1392.2302\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1262.6251 - val_loss: 1364.1198\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1233.0126 - val_loss: 1334.8745\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1202.2810 - val_loss: 1304.3052\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1170.2667 - val_loss: 1272.3818\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1137.0500 - val_loss: 1239.5640\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1102.8879 - val_loss: 1205.6161\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1067.8623 - val_loss: 1170.8954\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1032.1105 - val_loss: 1136.1060\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 996.2131 - val_loss: 1100.3247\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 959.8645 - val_loss: 1064.2603\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 923.2457 - val_loss: 1028.5221\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 887.1404 - val_loss: 992.7711\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 851.2562 - val_loss: 956.2087\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 814.9808 - val_loss: 921.5267\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 779.9959 - val_loss: 886.8293\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 745.4771 - val_loss: 852.6567\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 712.1874 - val_loss: 819.1080\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 679.5336 - val_loss: 786.8395\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 647.8145 - val_loss: 755.5170\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 617.7641 - val_loss: 724.3864\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 588.0948 - val_loss: 695.5080\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 560.8472 - val_loss: 667.1295\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 534.1788 - val_loss: 640.5945\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 509.0026 - val_loss: 615.4497\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 485.6534 - val_loss: 590.2018\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 462.5009 - val_loss: 567.3085\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 441.7685 - val_loss: 545.5165\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 422.1808 - val_loss: 525.2628\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 403.7988 - val_loss: 506.3878\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 387.1439 - val_loss: 487.7487\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 370.9457 - val_loss: 471.1089\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 356.1872 - val_loss: 455.1062\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 342.5547 - val_loss: 440.0213\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 329.8908 - val_loss: 426.0778\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 318.1370 - val_loss: 413.1785\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 307.3696 - val_loss: 400.8744\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 297.3472 - val_loss: 389.5038\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 288.1439 - val_loss: 378.3703\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 279.5134 - val_loss: 368.5512\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 271.5048 - val_loss: 359.0037\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 264.2470 - val_loss: 349.9395\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 257.4524 - val_loss: 341.0684\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 251.0587 - val_loss: 333.1687\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 245.1821 - val_loss: 325.6331\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 239.6884 - val_loss: 318.6198\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 234.7607 - val_loss: 311.9768\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 229.7752 - val_loss: 305.7252\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 225.5262 - val_loss: 299.3629\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 221.2189 - val_loss: 293.6768\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 217.2335 - val_loss: 288.0122\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 213.5025 - val_loss: 282.7720\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 209.9680 - val_loss: 277.9282\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 206.5715 - val_loss: 272.6826\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 203.2283 - val_loss: 268.1675\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 200.3226 - val_loss: 263.0671\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 197.1592 - val_loss: 259.1304\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 194.5342 - val_loss: 254.7292\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 191.8658 - val_loss: 250.6709\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 189.2988 - val_loss: 246.8159\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 186.8025 - val_loss: 243.0904\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 184.4507 - val_loss: 239.7872\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 182.3386 - val_loss: 236.0216\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 180.0520 - val_loss: 232.8981\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 178.0350 - val_loss: 229.4531\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.9672 - val_loss: 226.3983\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 174.0733 - val_loss: 223.3123\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 172.2341 - val_loss: 220.3607\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 170.4783 - val_loss: 217.4684\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 168.7854 - val_loss: 215.0577\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.1461 - val_loss: 212.7167\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 165.6022 - val_loss: 210.0758\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 164.0971 - val_loss: 207.8215\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 162.6812 - val_loss: 205.6568\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 161.1933 - val_loss: 203.3924\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 159.8511 - val_loss: 201.4759\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 158.6265 - val_loss: 199.5433\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 157.3423 - val_loss: 197.6654\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 156.1116 - val_loss: 196.1003\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 155.0113 - val_loss: 194.2797\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 153.8674 - val_loss: 192.6488\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 152.8773 - val_loss: 191.0165\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 151.8315 - val_loss: 189.6330\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 150.8280 - val_loss: 188.5093\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 149.9570 - val_loss: 187.0316\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 149.0380 - val_loss: 185.5780\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 148.1530 - val_loss: 184.6737\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 147.2886 - val_loss: 183.3456\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 146.4868 - val_loss: 181.9997\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 145.6258 - val_loss: 180.8753\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 144.7659 - val_loss: 180.1352\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 143.9943 - val_loss: 179.1771\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 143.2200 - val_loss: 178.0717\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 178.072\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1523.3892 - val_loss: 1625.0864\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1502.3109 - val_loss: 1604.4386\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1481.7026 - val_loss: 1583.8956\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1460.8903 - val_loss: 1563.1332\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1439.7804 - val_loss: 1542.0782\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1418.3961 - val_loss: 1520.7220\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1396.7520 - val_loss: 1498.8436\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1374.4319 - val_loss: 1477.0099\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1351.9706 - val_loss: 1453.7924\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1328.5692 - val_loss: 1430.3601\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1304.6306 - val_loss: 1405.8723\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1279.9331 - val_loss: 1380.5382\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1254.3794 - val_loss: 1354.7888\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1228.3737 - val_loss: 1328.0697\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1201.5383 - val_loss: 1300.2460\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1173.7136 - val_loss: 1271.5938\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1145.1368 - val_loss: 1242.1477\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1116.2251 - val_loss: 1212.1526\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1086.7418 - val_loss: 1181.1975\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1056.5641 - val_loss: 1150.1945\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1026.3171 - val_loss: 1118.5311\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 995.3870 - val_loss: 1086.1149\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 964.1025 - val_loss: 1053.7780\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 932.7996 - val_loss: 1021.3690\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 901.5419 - val_loss: 987.9061\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 870.4453 - val_loss: 954.5311\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 839.0227 - val_loss: 921.7583\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 808.0097 - val_loss: 889.2122\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 777.0747 - val_loss: 856.7346\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 746.2869 - val_loss: 823.8560\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 715.6040 - val_loss: 791.6869\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 685.7753 - val_loss: 759.3134\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 656.3666 - val_loss: 727.5834\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 627.3939 - val_loss: 697.0149\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 599.4344 - val_loss: 666.9135\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 572.3073 - val_loss: 637.2988\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 545.5995 - val_loss: 609.2767\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 520.4258 - val_loss: 581.5192\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 495.7088 - val_loss: 554.8671\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 472.1781 - val_loss: 529.2940\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 450.0311 - val_loss: 504.2722\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 428.6629 - val_loss: 480.5619\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 408.4329 - val_loss: 458.1772\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 389.2962 - val_loss: 436.7764\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 371.2122 - val_loss: 417.2135\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 354.6975 - val_loss: 398.0320\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 339.0138 - val_loss: 380.3701\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 324.7521 - val_loss: 363.8675\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 311.1556 - val_loss: 348.5957\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 298.8932 - val_loss: 334.4704\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 287.4794 - val_loss: 321.5335\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 277.3448 - val_loss: 309.3520\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 267.5974 - val_loss: 298.3498\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 258.8884 - val_loss: 288.4813\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 251.0836 - val_loss: 279.3907\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 244.0617 - val_loss: 270.7502\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 237.4088 - val_loss: 262.9310\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 231.3221 - val_loss: 256.1076\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 225.9264 - val_loss: 249.4371\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 220.8043 - val_loss: 243.7314\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 216.4878 - val_loss: 238.0011\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 212.1316 - val_loss: 233.2642\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 208.4930 - val_loss: 228.3272\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 204.8662 - val_loss: 224.3699\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 201.6307 - val_loss: 220.6698\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 198.6499 - val_loss: 216.8219\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 195.8833 - val_loss: 213.4744\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 193.2104 - val_loss: 210.6079\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 190.8499 - val_loss: 207.6532\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 188.5548 - val_loss: 205.0824\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 186.4493 - val_loss: 202.6561\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 184.4550 - val_loss: 200.3121\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 182.6155 - val_loss: 197.9744\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 180.7692 - val_loss: 196.0403\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 179.0766 - val_loss: 194.1807\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 177.4450 - val_loss: 192.3929\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 175.8741 - val_loss: 190.4996\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 174.3744 - val_loss: 188.8091\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 172.8696 - val_loss: 187.1789\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 171.5291 - val_loss: 185.8068\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.1944 - val_loss: 184.3084\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 168.8366 - val_loss: 182.9175\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 167.6324 - val_loss: 181.4875\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 166.3773 - val_loss: 180.1382\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.1604 - val_loss: 178.9748\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 164.0269 - val_loss: 177.5082\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 162.8893 - val_loss: 176.3648\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 161.7739 - val_loss: 175.0692\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 160.7435 - val_loss: 174.2675\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 159.6846 - val_loss: 173.0896\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 158.6652 - val_loss: 172.0238\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 157.7327 - val_loss: 170.8033\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 156.7670 - val_loss: 169.9348\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 155.7557 - val_loss: 168.9751\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 154.8893 - val_loss: 167.9309\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 153.9910 - val_loss: 166.9700\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 153.1818 - val_loss: 166.0291\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 152.4077 - val_loss: 165.2710\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 151.5766 - val_loss: 164.3105\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 150.7926 - val_loss: 163.5769\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 163.577\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 12ms/step - loss: 1658.5908 - val_loss: 1469.5037\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1640.0477 - val_loss: 1452.8658\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1622.1195 - val_loss: 1436.3057\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1604.3099 - val_loss: 1420.0685\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1586.5557 - val_loss: 1403.8430\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1568.7030 - val_loss: 1387.2765\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1550.6012 - val_loss: 1370.5337\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1532.4558 - val_loss: 1353.2159\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1513.3667 - val_loss: 1335.9481\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1493.9995 - val_loss: 1317.5924\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1473.5919 - val_loss: 1298.9719\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1452.5435 - val_loss: 1279.1215\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1430.3719 - val_loss: 1258.6533\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1407.0507 - val_loss: 1237.6504\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1383.1195 - val_loss: 1215.1046\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1357.5927 - val_loss: 1192.1129\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1331.5145 - val_loss: 1168.1044\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1304.1389 - val_loss: 1143.5525\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1276.1396 - val_loss: 1117.9894\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1247.3263 - val_loss: 1091.8268\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1217.3336 - val_loss: 1065.8646\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1187.3169 - val_loss: 1039.1179\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1156.5148 - val_loss: 1012.2337\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1125.5275 - val_loss: 985.3926\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1094.1831 - val_loss: 957.7379\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1062.3027 - val_loss: 930.5682\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1030.8522 - val_loss: 903.2740\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 999.0258 - val_loss: 876.0511\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 967.5867 - val_loss: 848.7235\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 935.6881 - val_loss: 821.8607\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 904.2576 - val_loss: 795.2260\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 872.9703 - val_loss: 768.7298\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 841.8845 - val_loss: 742.1674\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 810.8423 - val_loss: 716.6629\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 780.3549 - val_loss: 691.6537\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 750.5124 - val_loss: 666.5221\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 720.9432 - val_loss: 642.0785\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 691.5668 - val_loss: 618.6725\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 663.4542 - val_loss: 595.4028\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 635.5195 - val_loss: 572.8901\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 608.2795 - val_loss: 551.0652\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 581.5491 - val_loss: 530.4775\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 556.3014 - val_loss: 510.0982\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 531.3918 - val_loss: 490.5847\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 507.5440 - val_loss: 472.2272\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 484.8620 - val_loss: 454.3575\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 463.0643 - val_loss: 437.6656\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 442.3285 - val_loss: 421.6011\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 422.5958 - val_loss: 406.4136\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 404.0208 - val_loss: 392.1164\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 386.3867 - val_loss: 378.7403\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 369.8203 - val_loss: 366.6637\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 354.5466 - val_loss: 354.8664\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 340.2766 - val_loss: 343.7306\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 327.0735 - val_loss: 333.4911\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 314.7294 - val_loss: 324.2344\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 303.5612 - val_loss: 315.5346\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 293.2079 - val_loss: 307.3441\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 283.5961 - val_loss: 299.8264\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 274.7160 - val_loss: 292.5592\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.5907 - val_loss: 286.2715\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 259.3613 - val_loss: 280.1525\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 252.1939 - val_loss: 274.6247\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 246.0856 - val_loss: 269.2834\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 240.2192 - val_loss: 264.3518\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.7680 - val_loss: 259.8343\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 230.0624 - val_loss: 255.2684\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 225.1627 - val_loss: 251.3117\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 221.0859 - val_loss: 247.4234\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 216.9503 - val_loss: 243.8430\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 213.3957 - val_loss: 240.1582\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 209.8859 - val_loss: 236.7403\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 206.5568 - val_loss: 233.6310\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 203.5266 - val_loss: 230.6676\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 200.6357 - val_loss: 227.5943\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 197.8650 - val_loss: 224.7478\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 195.2604 - val_loss: 222.0078\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 192.8052 - val_loss: 219.2189\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 190.4501 - val_loss: 216.6698\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 188.1983 - val_loss: 214.2594\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.1618 - val_loss: 211.8750\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 184.2410 - val_loss: 209.7088\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 182.4729 - val_loss: 207.3782\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 180.6175 - val_loss: 205.6762\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 179.0378 - val_loss: 203.5947\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 177.3833 - val_loss: 201.7526\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.9026 - val_loss: 200.0579\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 174.3687 - val_loss: 198.2846\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 172.9915 - val_loss: 196.4557\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.6633 - val_loss: 194.7583\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.2830 - val_loss: 193.1440\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 169.0562 - val_loss: 191.6221\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 167.8880 - val_loss: 190.0201\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 166.6648 - val_loss: 188.5959\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.6554 - val_loss: 187.2676\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 164.5558 - val_loss: 185.7581\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 163.4891 - val_loss: 184.5141\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 162.5455 - val_loss: 183.3791\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 161.5056 - val_loss: 182.0206\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 160.5931 - val_loss: 180.8447\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 180.845\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1496.3124 - val_loss: 1542.8608\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1476.3350 - val_loss: 1522.2430\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1455.8728 - val_loss: 1501.4100\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1435.3665 - val_loss: 1479.8687\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1414.1051 - val_loss: 1458.0569\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1392.3199 - val_loss: 1435.5646\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1370.1156 - val_loss: 1412.4738\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1347.4448 - val_loss: 1388.7321\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1323.8578 - val_loss: 1364.6769\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1299.7583 - val_loss: 1339.4836\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1274.7858 - val_loss: 1313.5375\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1249.1455 - val_loss: 1287.1465\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1222.9962 - val_loss: 1259.9713\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1196.0737 - val_loss: 1232.4277\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1168.4407 - val_loss: 1203.8574\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1140.1102 - val_loss: 1175.2823\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1111.5446 - val_loss: 1145.6631\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1082.4364 - val_loss: 1115.8668\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1052.9141 - val_loss: 1085.2103\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1023.1974 - val_loss: 1054.8864\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 992.9953 - val_loss: 1024.9821\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 963.3966 - val_loss: 993.5378\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 933.2283 - val_loss: 963.3663\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 903.0565 - val_loss: 933.1555\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 873.3198 - val_loss: 902.5685\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 843.5326 - val_loss: 872.7347\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 814.1695 - val_loss: 842.9164\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 784.7863 - val_loss: 813.5337\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 756.1871 - val_loss: 784.6688\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 728.1675 - val_loss: 756.5220\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 700.8995 - val_loss: 728.3611\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 673.5301 - val_loss: 701.6358\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 647.5894 - val_loss: 675.6374\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 622.0925 - val_loss: 650.7108\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 597.5097 - val_loss: 626.1799\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 573.7118 - val_loss: 602.2272\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 550.6095 - val_loss: 579.8449\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 528.4482 - val_loss: 558.2238\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 507.3900 - val_loss: 537.0598\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 486.8910 - val_loss: 517.3596\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 467.5460 - val_loss: 497.9920\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 448.9300 - val_loss: 479.8449\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 430.9607 - val_loss: 463.2434\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 414.4351 - val_loss: 446.8616\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 398.6402 - val_loss: 431.0725\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 383.5774 - val_loss: 416.9967\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 369.5780 - val_loss: 403.5238\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 356.3720 - val_loss: 391.0292\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 344.2411 - val_loss: 378.6526\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 332.4533 - val_loss: 367.4673\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 321.5248 - val_loss: 357.0181\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 311.3677 - val_loss: 347.1035\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 301.7127 - val_loss: 338.1803\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 292.9195 - val_loss: 329.5013\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 284.6658 - val_loss: 321.5603\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 277.0178 - val_loss: 314.0827\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 269.8386 - val_loss: 307.2597\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 263.2414 - val_loss: 300.7217\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 256.9749 - val_loss: 294.6912\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 251.2654 - val_loss: 288.8098\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 245.7630 - val_loss: 283.5033\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 240.7556 - val_loss: 278.4442\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 236.1040 - val_loss: 273.6042\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 231.7885 - val_loss: 269.1460\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 227.7002 - val_loss: 264.9148\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.8347 - val_loss: 260.9627\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.2741 - val_loss: 257.1003\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 216.8610 - val_loss: 253.6536\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 213.6376 - val_loss: 250.2393\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.6772 - val_loss: 246.8077\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 207.7936 - val_loss: 243.7074\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 205.1675 - val_loss: 240.5788\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.5455 - val_loss: 237.7504\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 200.1662 - val_loss: 234.9745\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.8917 - val_loss: 232.3073\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 195.7399 - val_loss: 229.8231\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 193.6469 - val_loss: 227.2953\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 191.6829 - val_loss: 224.9472\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.8150 - val_loss: 222.7433\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 188.0197 - val_loss: 220.5203\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 186.2463 - val_loss: 218.3844\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.5458 - val_loss: 216.0744\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 182.8917 - val_loss: 214.1777\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 181.3197 - val_loss: 212.2254\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 179.8271 - val_loss: 210.1670\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 178.3492 - val_loss: 208.1788\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 176.9041 - val_loss: 206.2753\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.5091 - val_loss: 204.5749\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 174.2296 - val_loss: 202.5908\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 172.8427 - val_loss: 200.8675\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 171.5881 - val_loss: 199.2401\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 170.3672 - val_loss: 197.6362\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 169.1106 - val_loss: 196.1247\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.8967 - val_loss: 194.3882\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 166.7348 - val_loss: 192.7063\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.5608 - val_loss: 191.2950\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 164.4849 - val_loss: 189.8541\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 163.4083 - val_loss: 188.3961\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 162.3356 - val_loss: 186.8810\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 161.3225 - val_loss: 185.5532\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 185.553\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 1482.5865 - val_loss: 1635.7574\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1466.1600 - val_loss: 1618.6183\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1449.4310 - val_loss: 1600.6915\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1432.0773 - val_loss: 1582.0898\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1414.0931 - val_loss: 1562.8040\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1395.1375 - val_loss: 1542.8505\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1375.7900 - val_loss: 1521.3696\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1355.1437 - val_loss: 1498.9744\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1333.4287 - val_loss: 1475.6042\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1310.9858 - val_loss: 1450.6709\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1286.9521 - val_loss: 1425.0691\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1262.1326 - val_loss: 1397.2773\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1235.7271 - val_loss: 1368.6624\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1208.4430 - val_loss: 1338.4697\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1179.9076 - val_loss: 1307.4277\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1150.5524 - val_loss: 1274.7478\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1119.9517 - val_loss: 1242.0729\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1089.0399 - val_loss: 1207.8677\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1056.9156 - val_loss: 1173.3879\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1024.6763 - val_loss: 1137.5105\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 991.4903 - val_loss: 1102.3564\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 958.6602 - val_loss: 1066.2887\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 925.6424 - val_loss: 1030.0024\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 892.2380 - val_loss: 994.4810\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 859.4014 - val_loss: 958.9163\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 826.9846 - val_loss: 922.9921\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 794.3549 - val_loss: 888.5421\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 763.0386 - val_loss: 853.6584\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 731.6030 - val_loss: 820.4420\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 701.3787 - val_loss: 787.3782\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 671.7522 - val_loss: 755.6517\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 643.2260 - val_loss: 724.4426\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 615.7225 - val_loss: 694.5491\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 588.9600 - val_loss: 666.3337\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 563.6533 - val_loss: 638.5964\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 539.1080 - val_loss: 612.2548\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 516.0582 - val_loss: 586.4587\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 493.8776 - val_loss: 562.3639\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 472.8027 - val_loss: 540.3444\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 453.3003 - val_loss: 518.4888\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 434.5817 - val_loss: 497.8662\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 416.7685 - val_loss: 479.3324\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 400.6251 - val_loss: 461.1890\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 385.3455 - val_loss: 443.7045\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 370.7206 - val_loss: 428.3009\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 357.4153 - val_loss: 414.5249\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 345.2744 - val_loss: 400.3286\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 333.6662 - val_loss: 387.5064\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 322.9568 - val_loss: 375.4504\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 312.8979 - val_loss: 364.2570\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 303.6044 - val_loss: 353.9321\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 295.1252 - val_loss: 343.9373\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 287.0832 - val_loss: 335.0792\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 279.8795 - val_loss: 326.1884\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 272.9305 - val_loss: 318.3990\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.7696 - val_loss: 310.8613\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 260.8312 - val_loss: 304.1201\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 255.4590 - val_loss: 297.4241\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 250.3173 - val_loss: 291.4404\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 245.6113 - val_loss: 285.6216\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 241.1356 - val_loss: 280.2508\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 237.0636 - val_loss: 275.1145\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 233.3277 - val_loss: 270.3542\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.8590 - val_loss: 265.8844\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 226.4593 - val_loss: 261.8150\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.4489 - val_loss: 257.7395\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.5851 - val_loss: 254.0242\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 217.8638 - val_loss: 250.5620\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 215.2220 - val_loss: 247.2341\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 212.8873 - val_loss: 243.8349\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 210.5204 - val_loss: 240.8525\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 208.1467 - val_loss: 237.8707\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 205.9411 - val_loss: 235.0080\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 203.9442 - val_loss: 232.0664\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 201.8272 - val_loss: 229.3495\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 199.8281 - val_loss: 226.8024\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 197.9080 - val_loss: 224.4980\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 196.0179 - val_loss: 221.9008\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 194.1475 - val_loss: 219.5541\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 192.2759 - val_loss: 217.1573\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 190.5202 - val_loss: 215.0130\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 188.7692 - val_loss: 212.7005\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 187.1081 - val_loss: 210.4449\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 185.4096 - val_loss: 208.3769\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 183.7160 - val_loss: 206.2670\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 182.1630 - val_loss: 204.2129\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 180.5576 - val_loss: 202.3524\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 179.0695 - val_loss: 200.2496\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 177.5540 - val_loss: 198.1467\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.9964 - val_loss: 196.2396\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 174.4912 - val_loss: 194.4229\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 173.1288 - val_loss: 192.5655\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.6116 - val_loss: 190.7737\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 170.2347 - val_loss: 189.0842\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.9046 - val_loss: 187.7670\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 167.5779 - val_loss: 185.9049\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 166.0951 - val_loss: 184.4694\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 164.7631 - val_loss: 182.7821\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 163.4798 - val_loss: 181.2368\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 162.1406 - val_loss: 179.6714\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 179.671\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 14ms/step - loss: 1503.5378 - val_loss: 1725.7515\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1487.8280 - val_loss: 1708.6842\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1472.2002 - val_loss: 1691.5477\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1456.6307 - val_loss: 1674.2155\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1440.7268 - val_loss: 1656.4128\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1424.4635 - val_loss: 1638.1586\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1407.7917 - val_loss: 1619.2428\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1390.6957 - val_loss: 1599.7294\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1372.9833 - val_loss: 1579.4257\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1354.6147 - val_loss: 1558.4132\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1335.5603 - val_loss: 1536.7966\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1315.9186 - val_loss: 1514.2623\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1295.5997 - val_loss: 1490.9294\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1274.7153 - val_loss: 1467.1543\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1253.4485 - val_loss: 1442.4642\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1231.1733 - val_loss: 1417.5015\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1208.9188 - val_loss: 1390.8600\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1185.5342 - val_loss: 1364.7537\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1161.9912 - val_loss: 1337.6323\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1137.6987 - val_loss: 1309.6941\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1112.9580 - val_loss: 1280.5104\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1087.1123 - val_loss: 1251.7992\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1061.4672 - val_loss: 1222.4606\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1035.3608 - val_loss: 1191.8370\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1008.4800 - val_loss: 1161.3889\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 981.5041 - val_loss: 1130.8134\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 954.5303 - val_loss: 1100.3107\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 927.5054 - val_loss: 1070.0829\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 900.9869 - val_loss: 1039.4049\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 873.8184 - val_loss: 1008.9695\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 847.2449 - val_loss: 978.1735\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 820.5085 - val_loss: 948.5536\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 794.5633 - val_loss: 918.9572\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 768.4410 - val_loss: 889.7668\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 742.5726 - val_loss: 860.6505\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 716.7973 - val_loss: 832.6978\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 691.9056 - val_loss: 802.8893\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 666.5983 - val_loss: 775.4870\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 642.5644 - val_loss: 747.8942\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 618.4617 - val_loss: 721.5197\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 594.8770 - val_loss: 695.2783\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 571.8791 - val_loss: 669.5824\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 549.2124 - val_loss: 644.1007\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 526.7874 - val_loss: 620.6286\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 505.6659 - val_loss: 596.5554\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 484.6147 - val_loss: 573.2832\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 464.2205 - val_loss: 550.8804\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 444.6630 - val_loss: 529.1771\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 425.6207 - val_loss: 508.8943\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 407.4781 - val_loss: 488.9263\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 390.0016 - val_loss: 469.5237\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 373.5121 - val_loss: 450.6781\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 357.5563 - val_loss: 433.4707\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 342.7316 - val_loss: 417.1031\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 328.3275 - val_loss: 401.8983\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 315.0687 - val_loss: 386.9648\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 302.3701 - val_loss: 372.7570\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 290.2621 - val_loss: 359.9153\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 279.3392 - val_loss: 347.1296\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 268.6053 - val_loss: 335.6873\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 259.0679 - val_loss: 324.7270\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 249.8867 - val_loss: 315.1090\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 241.6727 - val_loss: 305.4395\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 233.8693 - val_loss: 296.8645\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 226.8704 - val_loss: 288.7656\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.3898 - val_loss: 281.3270\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.5504 - val_loss: 274.2974\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 209.0529 - val_loss: 268.1211\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 204.1167 - val_loss: 262.2166\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 199.7760 - val_loss: 256.6331\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 195.4668 - val_loss: 251.9433\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 191.7392 - val_loss: 247.6525\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 188.4548 - val_loss: 243.3153\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 185.4013 - val_loss: 239.4844\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 182.5454 - val_loss: 236.0700\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 180.0411 - val_loss: 232.8350\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 177.7984 - val_loss: 229.7446\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.6652 - val_loss: 226.9482\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 173.7208 - val_loss: 224.2447\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 171.9094 - val_loss: 221.8412\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.3565 - val_loss: 219.5667\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 168.8232 - val_loss: 217.4588\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.4726 - val_loss: 215.4378\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 166.1175 - val_loss: 213.6215\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 164.9034 - val_loss: 211.8170\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 163.7626 - val_loss: 210.1008\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 162.6587 - val_loss: 208.4409\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 161.6181 - val_loss: 206.8997\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 160.6224 - val_loss: 205.3546\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 159.6404 - val_loss: 203.9063\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 158.7207 - val_loss: 202.4566\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 157.8074 - val_loss: 201.1215\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 156.9637 - val_loss: 199.8399\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 156.0303 - val_loss: 198.5412\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 155.1649 - val_loss: 197.2419\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 154.3878 - val_loss: 195.9763\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 153.4695 - val_loss: 194.7360\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 152.7478 - val_loss: 193.5228\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 151.9063 - val_loss: 192.3714\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 151.1144 - val_loss: 191.2431\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 191.243\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1593.0813 - val_loss: 1576.3219\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1572.4225 - val_loss: 1556.5955\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1552.7208 - val_loss: 1537.4419\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1533.6470 - val_loss: 1518.4944\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1514.9934 - val_loss: 1499.9908\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1496.5958 - val_loss: 1481.5552\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1478.0548 - val_loss: 1463.2140\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1459.5880 - val_loss: 1444.5957\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1440.8462 - val_loss: 1425.7407\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1421.7343 - val_loss: 1407.0768\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1402.5768 - val_loss: 1387.6740\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1383.1129 - val_loss: 1367.6917\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1362.9714 - val_loss: 1347.5918\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1342.5917 - val_loss: 1326.8003\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1321.2980 - val_loss: 1305.9784\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1299.8729 - val_loss: 1284.0923\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1277.4767 - val_loss: 1261.7775\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1254.6572 - val_loss: 1238.9956\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1231.3866 - val_loss: 1215.9465\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1207.5817 - val_loss: 1192.4711\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1183.7837 - val_loss: 1167.8367\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1158.9722 - val_loss: 1143.8075\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1134.0985 - val_loss: 1119.7488\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1109.2865 - val_loss: 1094.2247\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1083.6785 - val_loss: 1069.4768\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1058.3887 - val_loss: 1044.1870\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1032.7128 - val_loss: 1018.8076\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1006.6041 - val_loss: 993.8769\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 980.8525 - val_loss: 968.4540\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 955.0295 - val_loss: 942.9275\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 928.9556 - val_loss: 917.9978\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 903.4055 - val_loss: 892.7100\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 877.7347 - val_loss: 867.6674\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 852.4244 - val_loss: 843.3936\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 827.7114 - val_loss: 819.2549\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 802.9847 - val_loss: 795.4975\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 778.4385 - val_loss: 772.3741\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 754.5410 - val_loss: 749.3365\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 731.1223 - val_loss: 726.7714\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 708.1387 - val_loss: 704.9921\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 685.7020 - val_loss: 683.3207\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 663.5856 - val_loss: 662.2509\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 642.0817 - val_loss: 641.7849\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 621.1337 - val_loss: 622.1777\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 600.9729 - val_loss: 602.1231\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 580.8782 - val_loss: 583.4821\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 561.8150 - val_loss: 565.5800\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 543.4766 - val_loss: 547.8628\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 525.4839 - val_loss: 530.9686\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 508.2005 - val_loss: 514.6871\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 491.6715 - val_loss: 498.7025\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 475.4000 - val_loss: 483.9569\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 460.2320 - val_loss: 469.0670\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 445.2935 - val_loss: 455.1998\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 431.1777 - val_loss: 441.6732\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 417.4651 - val_loss: 428.8268\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 404.6095 - val_loss: 416.2625\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 391.9342 - val_loss: 404.5651\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 380.0524 - val_loss: 393.3366\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 368.7643 - val_loss: 382.4361\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 358.0718 - val_loss: 371.8578\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 347.6617 - val_loss: 362.3104\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 337.9469 - val_loss: 352.9674\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 328.6355 - val_loss: 343.9133\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 319.7975 - val_loss: 335.3868\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 311.4817 - val_loss: 327.1628\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 303.6251 - val_loss: 319.5071\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 296.0116 - val_loss: 312.2971\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 288.9555 - val_loss: 305.3820\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 282.2614 - val_loss: 298.7663\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 275.8782 - val_loss: 292.4714\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 269.9207 - val_loss: 286.3926\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 264.2069 - val_loss: 280.7324\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 258.9027 - val_loss: 275.3986\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 253.7821 - val_loss: 270.3426\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 249.0837 - val_loss: 265.3595\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 244.5577 - val_loss: 260.7816\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 240.3549 - val_loss: 256.4892\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 236.3386 - val_loss: 252.4554\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 232.5853 - val_loss: 248.5380\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.0072 - val_loss: 244.9876\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 225.7589 - val_loss: 241.3139\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 222.5872 - val_loss: 237.9659\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 219.5266 - val_loss: 234.9535\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 216.6663 - val_loss: 231.9991\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 214.0462 - val_loss: 229.0089\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 211.6279 - val_loss: 226.3230\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 209.0284 - val_loss: 223.7280\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 206.8874 - val_loss: 221.2221\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.6742 - val_loss: 218.9764\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 202.6572 - val_loss: 216.7164\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 200.6416 - val_loss: 214.6427\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 198.8363 - val_loss: 212.4833\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.0556 - val_loss: 210.4554\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 195.2670 - val_loss: 208.4782\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 193.5421 - val_loss: 206.6633\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 191.9071 - val_loss: 204.8720\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 190.3334 - val_loss: 203.0559\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 188.8654 - val_loss: 201.3744\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 187.3669 - val_loss: 199.6930\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 199.693\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 12ms/step - loss: 1567.7122 - val_loss: 1555.2531\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1551.8643 - val_loss: 1539.8104\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1536.4707 - val_loss: 1524.7094\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1521.2020 - val_loss: 1509.8813\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1505.8503 - val_loss: 1495.2079\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1490.5576 - val_loss: 1480.3529\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1475.0215 - val_loss: 1464.8805\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1458.9529 - val_loss: 1449.0891\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1442.3478 - val_loss: 1433.0415\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1425.3254 - val_loss: 1416.0684\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1407.4406 - val_loss: 1398.5269\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1388.9924 - val_loss: 1380.0345\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1369.8207 - val_loss: 1360.5985\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1349.3358 - val_loss: 1340.7823\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1328.1718 - val_loss: 1319.8312\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1305.9248 - val_loss: 1297.4325\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1282.6266 - val_loss: 1274.0131\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1258.0500 - val_loss: 1249.4237\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1232.4067 - val_loss: 1223.5232\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1205.7056 - val_loss: 1196.6088\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1177.8794 - val_loss: 1169.1565\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1149.4717 - val_loss: 1140.7766\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1120.2457 - val_loss: 1111.8370\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1090.4200 - val_loss: 1081.7451\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1059.7373 - val_loss: 1052.1295\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1029.2217 - val_loss: 1020.8864\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 997.9544 - val_loss: 989.8065\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 966.6205 - val_loss: 958.6666\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 934.8588 - val_loss: 927.2257\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 903.3298 - val_loss: 894.8055\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 871.3248 - val_loss: 863.4088\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 839.6065 - val_loss: 831.5732\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 807.5513 - val_loss: 799.9706\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 776.1770 - val_loss: 767.9359\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 744.8888 - val_loss: 736.1088\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 713.6479 - val_loss: 705.5084\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 683.2703 - val_loss: 675.1004\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 653.8003 - val_loss: 645.3253\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 624.8014 - val_loss: 616.9324\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 597.2420 - val_loss: 588.5916\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 570.0011 - val_loss: 562.0267\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 544.0322 - val_loss: 536.0659\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 519.1746 - val_loss: 510.9813\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 495.5956 - val_loss: 487.1556\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 473.0946 - val_loss: 464.3637\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 451.4501 - val_loss: 443.6812\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 431.6460 - val_loss: 423.0188\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 412.5685 - val_loss: 404.1687\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 394.7787 - val_loss: 386.5403\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 378.4642 - val_loss: 369.3663\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 362.6360 - val_loss: 354.5178\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 348.3936 - val_loss: 339.8129\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 335.0692 - val_loss: 326.4820\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 322.5786 - val_loss: 314.4368\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 311.1592 - val_loss: 302.8056\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 300.6213 - val_loss: 291.9960\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 291.0348 - val_loss: 282.1316\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 282.0477 - val_loss: 273.5623\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 274.0622 - val_loss: 265.4056\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 266.6644 - val_loss: 258.0948\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 260.0426 - val_loss: 251.1593\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 253.6242 - val_loss: 245.5694\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 248.0082 - val_loss: 239.8328\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 242.7156 - val_loss: 234.6588\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 237.9952 - val_loss: 229.9973\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 233.4907 - val_loss: 225.7870\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.5204 - val_loss: 221.5957\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 225.7189 - val_loss: 218.0836\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 222.2006 - val_loss: 214.9447\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 218.9853 - val_loss: 211.8947\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 215.9668 - val_loss: 208.9363\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 212.9947 - val_loss: 206.2634\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 210.3801 - val_loss: 203.8634\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 207.8784 - val_loss: 201.7064\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 205.5078 - val_loss: 199.6775\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 203.2560 - val_loss: 197.7367\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 201.2568 - val_loss: 195.7899\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 199.2434 - val_loss: 194.0780\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 197.4052 - val_loss: 192.7246\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 195.6259 - val_loss: 191.0346\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 193.8748 - val_loss: 189.8182\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 192.2780 - val_loss: 188.5563\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 190.7189 - val_loss: 187.2450\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 189.2450 - val_loss: 185.9020\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 187.7838 - val_loss: 184.6757\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 186.3792 - val_loss: 183.6242\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 185.1189 - val_loss: 182.5595\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 183.6959 - val_loss: 181.6034\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 182.4376 - val_loss: 180.4630\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 181.1635 - val_loss: 179.5232\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 179.9702 - val_loss: 178.3021\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 178.6802 - val_loss: 177.5372\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 177.5798 - val_loss: 176.4832\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 176.4106 - val_loss: 175.6873\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.2629 - val_loss: 174.7416\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 174.0413 - val_loss: 173.8729\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 172.8943 - val_loss: 173.1259\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.7702 - val_loss: 172.2434\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 170.6819 - val_loss: 171.4823\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 169.6331 - val_loss: 170.7658\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 170.766\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 13ms/step - loss: 1525.7654 - val_loss: 1620.0936\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1510.2373 - val_loss: 1603.9238\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1494.7252 - val_loss: 1587.1965\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1478.4695 - val_loss: 1570.1552\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1461.7166 - val_loss: 1552.2533\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1444.1299 - val_loss: 1533.2715\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1425.3906 - val_loss: 1513.2699\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1405.7006 - val_loss: 1491.6165\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1384.3555 - val_loss: 1468.7690\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1361.8514 - val_loss: 1444.7020\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1338.4467 - val_loss: 1418.8225\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1313.5510 - val_loss: 1391.4143\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1287.1422 - val_loss: 1362.7131\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1259.3712 - val_loss: 1333.3828\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1230.7511 - val_loss: 1301.8783\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1200.8180 - val_loss: 1269.5265\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1169.8297 - val_loss: 1236.4484\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1138.3760 - val_loss: 1202.0704\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1105.5444 - val_loss: 1168.0941\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1072.9824 - val_loss: 1132.1111\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1039.3815 - val_loss: 1095.9589\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1005.6586 - val_loss: 1059.8250\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 971.4316 - val_loss: 1024.2186\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 937.6653 - val_loss: 988.0886\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 903.6924 - val_loss: 951.5134\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 869.3375 - val_loss: 916.3043\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 835.9192 - val_loss: 879.5028\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 801.3232 - val_loss: 844.5712\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 768.3845 - val_loss: 809.2755\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 735.3899 - val_loss: 775.6454\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 703.7398 - val_loss: 741.6100\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 671.6286 - val_loss: 709.6009\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 641.2860 - val_loss: 677.7800\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 611.9314 - val_loss: 647.5141\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 583.7935 - val_loss: 618.6741\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 556.9955 - val_loss: 590.3038\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 530.9076 - val_loss: 564.5176\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 506.8731 - val_loss: 539.0849\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 483.3198 - val_loss: 515.6878\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 461.2427 - val_loss: 493.4398\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 440.6378 - val_loss: 471.7960\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 420.9928 - val_loss: 451.6621\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 402.4623 - val_loss: 433.2717\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 385.4124 - val_loss: 415.4050\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 369.2850 - val_loss: 398.7390\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 354.1907 - val_loss: 383.2845\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 340.1911 - val_loss: 368.5933\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 327.2490 - val_loss: 355.3250\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 315.4325 - val_loss: 342.9735\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 304.3765 - val_loss: 331.3476\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 293.9755 - val_loss: 320.4130\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 284.2462 - val_loss: 310.3391\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 275.2745 - val_loss: 300.2189\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.6943 - val_loss: 291.5365\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 259.0522 - val_loss: 283.5316\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 251.9861 - val_loss: 275.7105\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 245.2744 - val_loss: 268.6740\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 239.2768 - val_loss: 261.7070\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 233.4922 - val_loss: 255.7486\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 228.2400 - val_loss: 249.6586\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 223.2276 - val_loss: 244.3590\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 218.5625 - val_loss: 239.5426\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.3473 - val_loss: 234.6370\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.0769 - val_loss: 230.1096\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 206.0625 - val_loss: 226.0239\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.4811 - val_loss: 221.5848\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 198.7445 - val_loss: 217.8450\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 195.4234 - val_loss: 214.0886\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 192.1848 - val_loss: 210.8134\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.2233 - val_loss: 207.4816\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 186.2617 - val_loss: 204.7054\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 183.6238 - val_loss: 201.8131\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 180.9741 - val_loss: 199.0345\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 178.4909 - val_loss: 196.3786\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.1569 - val_loss: 194.0183\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 173.9398 - val_loss: 191.6610\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.7753 - val_loss: 189.4905\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 169.6061 - val_loss: 187.6193\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 167.7078 - val_loss: 185.5855\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.6939 - val_loss: 183.7849\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 163.9757 - val_loss: 181.9350\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.1694 - val_loss: 180.3596\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 160.5090 - val_loss: 178.7567\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 158.9197 - val_loss: 177.3181\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 157.4792 - val_loss: 175.9088\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 156.0639 - val_loss: 174.7778\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 154.7788 - val_loss: 173.5288\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 153.5423 - val_loss: 172.1912\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 152.2493 - val_loss: 171.1021\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 151.1020 - val_loss: 170.2345\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 149.8966 - val_loss: 169.1280\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 148.8503 - val_loss: 168.0924\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 147.7505 - val_loss: 167.2408\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 146.7092 - val_loss: 166.3099\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 145.7229 - val_loss: 165.4513\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 144.5671 - val_loss: 164.5841\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 143.6245 - val_loss: 163.6432\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 142.6391 - val_loss: 163.0087\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 141.7146 - val_loss: 162.1125\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 140.8303 - val_loss: 161.4422\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 161.442\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 21ms/step - loss: 1617.2786 - val_loss: 1505.3788\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1604.3833 - val_loss: 1492.8799\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1591.1521 - val_loss: 1480.4104\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1577.6184 - val_loss: 1466.9722\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1562.9567 - val_loss: 1452.9302\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1547.5411 - val_loss: 1437.4753\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1530.6914 - val_loss: 1421.1127\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1512.6129 - val_loss: 1403.2709\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1492.7678 - val_loss: 1383.9730\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1471.4023 - val_loss: 1363.2106\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1448.4427 - val_loss: 1341.0253\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1423.7328 - val_loss: 1317.1472\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1397.3243 - val_loss: 1291.7264\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1369.0013 - val_loss: 1265.1301\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1339.4849 - val_loss: 1236.0200\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1308.2084 - val_loss: 1206.2775\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1275.7633 - val_loss: 1175.4601\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1242.3563 - val_loss: 1143.2728\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1207.6455 - val_loss: 1110.4036\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1171.9507 - val_loss: 1077.0341\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1135.5641 - val_loss: 1043.0823\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1098.9155 - val_loss: 1008.1301\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1061.6261 - val_loss: 973.1744\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1024.0443 - val_loss: 938.3613\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 986.7966 - val_loss: 902.4504\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 949.4189 - val_loss: 867.4532\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 912.3565 - val_loss: 833.7280\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 876.4429 - val_loss: 799.9067\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 840.7101 - val_loss: 766.3315\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 805.8594 - val_loss: 733.0137\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 771.1420 - val_loss: 701.0924\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 738.2254 - val_loss: 669.5408\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 705.7162 - val_loss: 639.5732\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 674.1631 - val_loss: 611.0670\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 644.3027 - val_loss: 582.2166\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 615.2341 - val_loss: 555.3162\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 587.6248 - val_loss: 529.9798\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 561.3972 - val_loss: 505.0659\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 536.0418 - val_loss: 482.0898\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 512.8336 - val_loss: 459.4287\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 490.3247 - val_loss: 438.3755\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 469.1443 - val_loss: 418.9655\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 449.4917 - val_loss: 400.8615\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 431.2745 - val_loss: 383.2459\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 413.8069 - val_loss: 367.0793\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 397.8145 - val_loss: 352.0741\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 382.9173 - val_loss: 338.3232\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 369.0083 - val_loss: 325.4456\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 356.2812 - val_loss: 313.4449\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 344.4791 - val_loss: 302.1997\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 333.2681 - val_loss: 292.2000\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 323.2374 - val_loss: 282.8147\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 313.7540 - val_loss: 274.2492\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 304.9812 - val_loss: 266.3289\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 297.0897 - val_loss: 258.9613\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 289.5881 - val_loss: 252.3232\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 282.7424 - val_loss: 246.0101\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 276.2910 - val_loss: 240.2684\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 270.3041 - val_loss: 235.0307\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 264.7565 - val_loss: 230.0112\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 259.7729 - val_loss: 225.4329\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 254.7782 - val_loss: 221.2346\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 250.1922 - val_loss: 217.3151\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 245.9904 - val_loss: 213.6091\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 241.9554 - val_loss: 209.9505\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 238.0427 - val_loss: 206.7366\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.5653 - val_loss: 203.5224\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 231.0486 - val_loss: 200.6711\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 227.7916 - val_loss: 198.0303\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 224.7121 - val_loss: 195.3931\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 221.7040 - val_loss: 192.8732\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 218.9000 - val_loss: 190.3038\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 216.0153 - val_loss: 188.1306\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 213.4691 - val_loss: 185.9279\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 210.8633 - val_loss: 183.8202\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 208.4645 - val_loss: 181.7783\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 206.0100 - val_loss: 179.9125\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 203.7483 - val_loss: 178.0262\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.5026 - val_loss: 176.3091\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 199.4197 - val_loss: 174.5131\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.2769 - val_loss: 172.8305\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 195.3407 - val_loss: 171.2732\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 193.3859 - val_loss: 169.6563\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 191.5802 - val_loss: 167.9874\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 189.5981 - val_loss: 166.6346\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 187.8698 - val_loss: 165.1464\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.0217 - val_loss: 163.7376\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 184.2758 - val_loss: 162.3275\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 182.6126 - val_loss: 160.8494\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 180.8899 - val_loss: 159.4521\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 179.2002 - val_loss: 158.2298\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 177.6581 - val_loss: 157.0346\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 175.9560 - val_loss: 155.7448\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 174.4719 - val_loss: 154.5012\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 172.8365 - val_loss: 153.4565\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 171.4145 - val_loss: 152.1969\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 169.9056 - val_loss: 150.9801\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 168.4199 - val_loss: 149.8795\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 167.0161 - val_loss: 148.7117\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.5764 - val_loss: 147.6286\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 147.629\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 19ms/step - loss: 1482.0878 - val_loss: 1681.3081\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1467.2611 - val_loss: 1664.5266\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1452.5824 - val_loss: 1647.9590\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1437.9486 - val_loss: 1631.0933\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1423.1862 - val_loss: 1613.8219\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1407.7935 - val_loss: 1596.5775\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1392.2106 - val_loss: 1578.3276\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1376.0118 - val_loss: 1559.4854\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1359.1007 - val_loss: 1539.9358\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1341.3801 - val_loss: 1519.4673\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1323.0876 - val_loss: 1497.8977\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1304.0249 - val_loss: 1475.9249\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1284.2168 - val_loss: 1453.1244\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1263.6835 - val_loss: 1429.2233\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1242.5475 - val_loss: 1404.2261\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1220.2821 - val_loss: 1378.7122\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1197.2968 - val_loss: 1352.1519\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1173.6455 - val_loss: 1324.3551\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1148.8518 - val_loss: 1295.8610\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1123.5669 - val_loss: 1265.9885\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1097.3081 - val_loss: 1235.5613\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1070.3412 - val_loss: 1204.0677\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1042.0514 - val_loss: 1172.6766\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1013.8789 - val_loss: 1139.3694\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 984.9697 - val_loss: 1105.5221\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 955.1074 - val_loss: 1071.7463\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 925.4603 - val_loss: 1037.4242\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 895.3756 - val_loss: 1004.0037\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 865.9440 - val_loss: 970.0514\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 836.5372 - val_loss: 936.3698\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 807.0504 - val_loss: 903.8056\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 778.3196 - val_loss: 870.8041\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 750.1013 - val_loss: 838.0234\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 722.2119 - val_loss: 806.8972\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 695.3146 - val_loss: 776.5355\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 668.8996 - val_loss: 747.3293\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 644.2232 - val_loss: 718.2930\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 619.6919 - val_loss: 690.8552\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 596.4553 - val_loss: 663.9268\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 573.6359 - val_loss: 638.7344\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 552.1451 - val_loss: 614.4023\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 531.7839 - val_loss: 590.8506\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 512.5844 - val_loss: 567.8456\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 493.8759 - val_loss: 546.9951\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 476.3448 - val_loss: 526.7742\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 459.9153 - val_loss: 507.2026\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 444.0681 - val_loss: 489.1452\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 429.4024 - val_loss: 471.7920\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 415.4321 - val_loss: 454.6665\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 401.9835 - val_loss: 439.3882\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 389.5384 - val_loss: 424.8087\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 378.1155 - val_loss: 410.4612\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 366.9268 - val_loss: 397.3958\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 356.6069 - val_loss: 385.2203\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 346.9359 - val_loss: 373.4844\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 337.8949 - val_loss: 362.6479\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 329.2895 - val_loss: 352.3306\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 321.3144 - val_loss: 342.5879\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 313.6336 - val_loss: 333.6576\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 306.5361 - val_loss: 325.0107\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 299.8437 - val_loss: 316.7566\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 293.3918 - val_loss: 309.0928\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 287.5794 - val_loss: 301.0991\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 281.6380 - val_loss: 294.3707\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 276.2548 - val_loss: 288.3488\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 271.2690 - val_loss: 282.0365\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.2353 - val_loss: 276.3741\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 261.6678 - val_loss: 270.4627\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 256.9945 - val_loss: 265.2529\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 252.7330 - val_loss: 259.9192\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 248.7437 - val_loss: 255.0726\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 244.6209 - val_loss: 250.4540\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 240.8940 - val_loss: 246.5303\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 237.2360 - val_loss: 242.0222\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 233.5607 - val_loss: 238.1129\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 230.0101 - val_loss: 234.0634\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 226.5765 - val_loss: 230.1129\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.0362 - val_loss: 226.8343\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 219.8441 - val_loss: 223.1392\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 216.5318 - val_loss: 220.1443\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 213.4068 - val_loss: 216.7495\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 210.2098 - val_loss: 213.7139\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 207.1049 - val_loss: 210.6036\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 204.0225 - val_loss: 207.6153\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.0476 - val_loss: 204.4844\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 198.1042 - val_loss: 201.6427\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 195.1932 - val_loss: 198.7084\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 192.3857 - val_loss: 195.9778\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 189.4615 - val_loss: 193.4239\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.7768 - val_loss: 190.7533\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 183.9636 - val_loss: 187.9776\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 181.1250 - val_loss: 185.6884\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 178.3591 - val_loss: 183.1876\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 175.7102 - val_loss: 181.1685\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 173.1460 - val_loss: 178.7300\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.5779 - val_loss: 176.3156\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.1172 - val_loss: 174.2291\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 165.7628 - val_loss: 172.2548\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 163.4694 - val_loss: 170.2794\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 161.1600 - val_loss: 168.2076\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 168.208\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1690.8118 - val_loss: 1336.1489\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1671.2917 - val_loss: 1321.0758\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1652.5151 - val_loss: 1306.6494\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1634.0776 - val_loss: 1292.6870\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1616.0210 - val_loss: 1278.7498\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1597.7864 - val_loss: 1264.7140\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1579.3536 - val_loss: 1250.3970\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1560.5425 - val_loss: 1236.0095\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1541.0726 - val_loss: 1221.4301\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1520.9304 - val_loss: 1206.2891\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1500.1709 - val_loss: 1190.7390\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1478.9539 - val_loss: 1174.6244\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1456.8237 - val_loss: 1158.4137\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1434.1281 - val_loss: 1141.7573\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1410.6151 - val_loss: 1124.3739\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1386.6703 - val_loss: 1106.5248\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1361.5088 - val_loss: 1088.7249\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1336.4052 - val_loss: 1070.1235\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1310.1237 - val_loss: 1051.2662\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1283.8344 - val_loss: 1031.9125\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1256.8292 - val_loss: 1012.5054\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1229.3093 - val_loss: 992.8810\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1202.0243 - val_loss: 972.7402\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1173.8928 - val_loss: 952.5180\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1145.6516 - val_loss: 932.4284\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1117.5000 - val_loss: 912.1337\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1089.0245 - val_loss: 891.5471\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1060.5513 - val_loss: 871.0685\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1032.1234 - val_loss: 850.4774\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1003.5745 - val_loss: 830.0217\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 975.0512 - val_loss: 809.4903\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 946.8328 - val_loss: 788.7522\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 918.5889 - val_loss: 768.2259\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 890.2900 - val_loss: 747.4847\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 862.2785 - val_loss: 726.7271\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 834.5711 - val_loss: 706.1456\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 806.9792 - val_loss: 685.8062\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 780.1445 - val_loss: 665.3983\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 753.3320 - val_loss: 645.1256\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 726.9138 - val_loss: 625.6473\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 701.5789 - val_loss: 605.7936\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 676.1700 - val_loss: 587.1564\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 652.0016 - val_loss: 568.0302\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 627.8099 - val_loss: 549.3992\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 604.6592 - val_loss: 531.0908\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 581.6697 - val_loss: 513.2776\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 559.6580 - val_loss: 495.3740\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 537.8770 - val_loss: 477.7011\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 516.5937 - val_loss: 460.1646\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 495.8506 - val_loss: 442.6491\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 475.4732 - val_loss: 425.7804\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 455.7751 - val_loss: 409.4026\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 436.8936 - val_loss: 393.4049\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 418.7927 - val_loss: 378.2748\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 401.4331 - val_loss: 363.6476\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 384.9883 - val_loss: 350.3894\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 369.5255 - val_loss: 337.2880\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 355.0589 - val_loss: 324.7727\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 341.3723 - val_loss: 313.1782\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 328.4730 - val_loss: 302.7234\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 316.5258 - val_loss: 292.9299\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 305.3076 - val_loss: 283.7307\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 294.9802 - val_loss: 275.3679\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 285.3003 - val_loss: 267.6346\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 276.3806 - val_loss: 260.2842\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 267.9142 - val_loss: 253.8051\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 260.2713 - val_loss: 247.8391\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 253.2414 - val_loss: 242.2599\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 246.5542 - val_loss: 237.3114\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 240.5492 - val_loss: 232.9442\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 235.1747 - val_loss: 228.6848\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 230.0741 - val_loss: 224.7507\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 225.3338 - val_loss: 221.9440\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 221.0640 - val_loss: 218.4071\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 216.8646 - val_loss: 215.6188\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 213.1713 - val_loss: 212.5893\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 209.6113 - val_loss: 210.1021\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 206.3124 - val_loss: 207.7526\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 203.3316 - val_loss: 205.5707\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 200.3990 - val_loss: 203.3340\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 197.6961 - val_loss: 201.3851\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 195.1468 - val_loss: 199.5928\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 192.8537 - val_loss: 197.9275\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 190.7353 - val_loss: 196.3040\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 188.6005 - val_loss: 194.6187\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.6015 - val_loss: 192.9969\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 184.6962 - val_loss: 191.4686\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 182.9572 - val_loss: 190.1447\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 181.2178 - val_loss: 188.5993\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 179.5485 - val_loss: 187.1015\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 177.9122 - val_loss: 185.5657\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 176.2338 - val_loss: 184.1527\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 174.6681 - val_loss: 182.7292\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 173.0671 - val_loss: 181.4171\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 171.5901 - val_loss: 180.1888\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 170.0175 - val_loss: 178.7488\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 168.5001 - val_loss: 177.3111\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 167.0248 - val_loss: 176.0970\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.5669 - val_loss: 174.8573\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 164.1330 - val_loss: 173.6662\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 173.666\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 16ms/step - loss: 1594.6709 - val_loss: 1445.8876\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1582.0358 - val_loss: 1433.5289\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1569.4805 - val_loss: 1420.7538\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1556.5640 - val_loss: 1407.3989\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1543.0364 - val_loss: 1393.5470\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1528.8652 - val_loss: 1378.5558\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1513.3398 - val_loss: 1362.6256\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1496.5925 - val_loss: 1344.9119\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1477.8766 - val_loss: 1325.7874\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1457.4155 - val_loss: 1304.2621\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1434.7046 - val_loss: 1280.9443\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1409.8955 - val_loss: 1255.1436\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1382.6849 - val_loss: 1227.0507\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1353.0052 - val_loss: 1197.0669\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1321.1978 - val_loss: 1164.7415\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1287.0417 - val_loss: 1130.8062\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1251.1144 - val_loss: 1094.8080\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1213.5000 - val_loss: 1056.6924\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1174.1133 - val_loss: 1017.8254\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1133.1451 - val_loss: 978.2703\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1091.3920 - val_loss: 938.1257\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1048.7867 - val_loss: 897.7689\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1006.4645 - val_loss: 855.9899\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 963.1552 - val_loss: 815.7340\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 920.5860 - val_loss: 775.5881\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 878.0371 - val_loss: 737.1175\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 836.8643 - val_loss: 699.0876\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 796.0477 - val_loss: 662.3088\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 756.4738 - val_loss: 626.4609\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 717.6751 - val_loss: 591.7634\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 680.4565 - val_loss: 559.0330\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 644.4253 - val_loss: 527.8713\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 610.6096 - val_loss: 498.5329\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 577.7662 - val_loss: 471.3641\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 546.8603 - val_loss: 446.0829\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 517.9423 - val_loss: 421.9413\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 490.3371 - val_loss: 400.0722\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 464.9358 - val_loss: 380.0529\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 441.1068 - val_loss: 361.5934\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 419.2442 - val_loss: 344.7586\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 398.7029 - val_loss: 329.9382\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 380.1469 - val_loss: 316.2594\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 362.7888 - val_loss: 303.9097\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 347.0312 - val_loss: 292.8370\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 332.2629 - val_loss: 283.1299\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 319.0441 - val_loss: 274.3702\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 307.2003 - val_loss: 266.1658\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 296.0219 - val_loss: 259.3383\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 286.0041 - val_loss: 253.0855\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 276.9822 - val_loss: 247.6270\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 268.9239 - val_loss: 242.6723\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 261.2698 - val_loss: 238.2094\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 254.3772 - val_loss: 234.0064\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 248.2004 - val_loss: 230.6006\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 242.5875 - val_loss: 227.3130\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 237.3087 - val_loss: 224.2040\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 232.5193 - val_loss: 221.3648\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 228.3856 - val_loss: 218.9919\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 224.0926 - val_loss: 216.4832\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.4819 - val_loss: 213.9410\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 217.0097 - val_loss: 211.9372\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 213.7678 - val_loss: 209.9026\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.7659 - val_loss: 208.0102\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 207.9135 - val_loss: 205.8095\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 205.2456 - val_loss: 204.1095\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.8904 - val_loss: 202.3495\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 200.5722 - val_loss: 200.6047\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 198.4045 - val_loss: 198.7417\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 196.3711 - val_loss: 197.3646\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 194.3986 - val_loss: 195.5976\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.6330 - val_loss: 194.4275\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 190.7862 - val_loss: 192.4350\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.1786 - val_loss: 191.2839\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 187.5241 - val_loss: 189.2450\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 186.0361 - val_loss: 187.4764\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 184.5013 - val_loss: 186.4951\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 183.0962 - val_loss: 184.7746\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 181.7531 - val_loss: 183.4492\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 180.4346 - val_loss: 182.2245\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 179.2036 - val_loss: 180.6753\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 177.9182 - val_loss: 179.2477\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.8125 - val_loss: 177.9583\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 175.6572 - val_loss: 176.8144\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 174.5604 - val_loss: 175.7818\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 173.3741 - val_loss: 174.0962\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 172.3215 - val_loss: 172.8940\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 171.2921 - val_loss: 171.7959\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 170.2691 - val_loss: 170.7583\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 169.3236 - val_loss: 169.2150\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.4491 - val_loss: 168.7072\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 167.4921 - val_loss: 167.4043\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 166.7042 - val_loss: 166.9317\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 165.8187 - val_loss: 165.8456\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 165.0669 - val_loss: 165.2088\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 164.3923 - val_loss: 164.4193\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 163.6217 - val_loss: 163.5502\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.9179 - val_loss: 162.7091\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 162.2599 - val_loss: 161.7581\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 161.6664 - val_loss: 161.3288\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 160.9068 - val_loss: 160.6629\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 160.663\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 16ms/step - loss: 1554.3589 - val_loss: 1584.3220\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1539.9161 - val_loss: 1569.9357\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1525.7827 - val_loss: 1555.4342\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1511.5721 - val_loss: 1541.0973\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1497.6583 - val_loss: 1526.2516\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 1483.1353 - val_loss: 1511.2650\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1468.4521 - val_loss: 1495.9602\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1453.5431 - val_loss: 1479.5991\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1437.7179 - val_loss: 1463.1946\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1421.6544 - val_loss: 1445.9348\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1404.7731 - val_loss: 1428.1156\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1387.3087 - val_loss: 1409.5219\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1369.0347 - val_loss: 1390.1292\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1350.1503 - val_loss: 1369.8911\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1330.2472 - val_loss: 1349.2073\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1309.9048 - val_loss: 1327.2473\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1288.4260 - val_loss: 1304.6029\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1266.0469 - val_loss: 1280.9359\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 1242.8197 - val_loss: 1256.0709\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1218.4998 - val_loss: 1230.2572\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1193.0151 - val_loss: 1203.8098\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1166.7131 - val_loss: 1176.1387\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1139.3840 - val_loss: 1148.1318\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1111.5125 - val_loss: 1119.1403\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1082.7727 - val_loss: 1089.4661\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1053.6769 - val_loss: 1059.4241\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1024.2369 - val_loss: 1028.9116\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 994.1550 - val_loss: 998.7012\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 963.5624 - val_loss: 968.1628\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 933.2460 - val_loss: 936.0437\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 901.5831 - val_loss: 904.6924\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 870.2734 - val_loss: 872.7277\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 838.4338 - val_loss: 840.8123\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 806.3311 - val_loss: 809.4617\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 775.0080 - val_loss: 777.5305\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 743.2228 - val_loss: 747.0540\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 712.8685 - val_loss: 716.5671\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 682.3651 - val_loss: 687.3958\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 653.3114 - val_loss: 658.5552\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 624.5732 - val_loss: 631.1579\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 597.2489 - val_loss: 604.4532\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 570.9273 - val_loss: 578.5921\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 545.5890 - val_loss: 554.2821\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 521.5272 - val_loss: 531.2850\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 498.6285 - val_loss: 508.9639\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 476.5393 - val_loss: 488.1256\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 455.8060 - val_loss: 468.1372\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 436.3609 - val_loss: 449.0557\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 417.7570 - val_loss: 431.3740\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 400.2546 - val_loss: 414.4479\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 383.6563 - val_loss: 399.0493\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 368.4747 - val_loss: 383.7768\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 353.7502 - val_loss: 369.8470\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 340.3781 - val_loss: 356.4734\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 327.5734 - val_loss: 344.4405\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 316.0056 - val_loss: 332.6347\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 304.7755 - val_loss: 321.8972\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 294.4845 - val_loss: 311.5731\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 284.8188 - val_loss: 301.9333\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 275.7755 - val_loss: 292.8874\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 267.3319 - val_loss: 284.6863\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 259.6539 - val_loss: 276.7427\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 252.3692 - val_loss: 269.3102\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 245.6293 - val_loss: 262.4631\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 239.4031 - val_loss: 255.7702\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 233.6240 - val_loss: 249.6026\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 228.3503 - val_loss: 244.0413\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.5399 - val_loss: 238.9495\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 218.8784 - val_loss: 234.1490\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.8271 - val_loss: 229.6790\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 210.9187 - val_loss: 225.5741\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 207.4309 - val_loss: 221.5210\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 204.1461 - val_loss: 218.0301\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 201.1445 - val_loss: 214.6085\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 198.4539 - val_loss: 211.3872\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 195.7732 - val_loss: 208.6078\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 193.4273 - val_loss: 205.6977\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 191.2446 - val_loss: 202.8583\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 189.0969 - val_loss: 200.6071\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 187.2567 - val_loss: 198.2875\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 185.4133 - val_loss: 196.1084\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 183.8128 - val_loss: 194.1399\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 182.2523 - val_loss: 192.1927\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 180.7800 - val_loss: 190.4951\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 179.4630 - val_loss: 188.6526\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 178.0804 - val_loss: 187.0474\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.7980 - val_loss: 185.4534\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 175.5439 - val_loss: 183.9894\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 174.3907 - val_loss: 182.3366\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 173.2133 - val_loss: 181.0443\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 172.1009 - val_loss: 179.6071\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.9884 - val_loss: 178.3922\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.0337 - val_loss: 177.3002\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 169.0355 - val_loss: 176.0936\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 168.0676 - val_loss: 174.9159\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 167.1340 - val_loss: 173.8741\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 166.2444 - val_loss: 172.9447\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 165.3973 - val_loss: 171.9589\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 164.4860 - val_loss: 170.9293\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 163.6670 - val_loss: 170.0276\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 170.028\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 16ms/step - loss: 1643.4125 - val_loss: 1520.7576\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1624.9075 - val_loss: 1503.3252\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1606.9526 - val_loss: 1486.7076\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1589.5170 - val_loss: 1470.2640\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1572.0862 - val_loss: 1454.0227\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1554.9896 - val_loss: 1437.5170\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1537.4896 - val_loss: 1421.4624\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1520.0830 - val_loss: 1404.9036\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1502.3875 - val_loss: 1387.8940\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1484.3625 - val_loss: 1370.4921\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1465.6749 - val_loss: 1352.9600\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1446.5521 - val_loss: 1334.8694\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1427.0533 - val_loss: 1316.0841\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1406.9266 - val_loss: 1296.9039\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1386.1510 - val_loss: 1276.9220\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1364.6443 - val_loss: 1256.3923\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1342.5280 - val_loss: 1235.1421\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1319.7169 - val_loss: 1212.9875\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1296.2954 - val_loss: 1190.5731\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1272.3499 - val_loss: 1167.6410\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1247.6993 - val_loss: 1144.2611\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1222.4348 - val_loss: 1120.3406\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1196.8999 - val_loss: 1095.3600\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1170.4906 - val_loss: 1070.6060\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1143.8267 - val_loss: 1045.6228\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1117.0101 - val_loss: 1019.8625\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1089.6178 - val_loss: 994.2867\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1062.4269 - val_loss: 968.5527\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1034.8914 - val_loss: 942.9354\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1007.3730 - val_loss: 916.9882\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 979.9527 - val_loss: 890.9778\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 952.0320 - val_loss: 865.9520\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 925.2407 - val_loss: 840.1107\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 897.7327 - val_loss: 815.2231\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 870.8806 - val_loss: 790.4689\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 844.2087 - val_loss: 765.9351\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 817.8851 - val_loss: 741.9689\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 792.1652 - val_loss: 718.2479\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 766.6218 - val_loss: 694.8427\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 741.6369 - val_loss: 672.1243\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 717.4434 - val_loss: 649.7052\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 693.4836 - val_loss: 628.4205\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 670.4881 - val_loss: 607.5759\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 647.7031 - val_loss: 587.3914\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 625.7909 - val_loss: 568.1240\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 604.6552 - val_loss: 549.1090\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 584.3413 - val_loss: 530.7443\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 564.2292 - val_loss: 513.5455\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 545.2637 - val_loss: 496.3695\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 526.6639 - val_loss: 480.3655\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 509.1152 - val_loss: 464.9495\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 492.2401 - val_loss: 450.1967\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 475.9609 - val_loss: 436.0832\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 460.3811 - val_loss: 423.0399\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 445.7127 - val_loss: 410.6315\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 432.1959 - val_loss: 398.3829\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 418.6336 - val_loss: 387.3665\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 406.2701 - val_loss: 376.6979\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 394.2047 - val_loss: 366.9421\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 383.1744 - val_loss: 357.4245\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 372.3898 - val_loss: 348.7875\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 362.5168 - val_loss: 340.4626\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 353.0226 - val_loss: 332.8391\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 344.1934 - val_loss: 325.6962\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 335.9623 - val_loss: 319.0243\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 328.2755 - val_loss: 312.7359\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 320.9730 - val_loss: 306.8096\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 313.9932 - val_loss: 301.5269\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 307.6524 - val_loss: 296.5686\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 301.6056 - val_loss: 291.9346\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 296.0279 - val_loss: 287.4842\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 290.6329 - val_loss: 283.6027\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 285.7698 - val_loss: 279.7567\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 281.1109 - val_loss: 276.2225\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 276.7548 - val_loss: 272.9438\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 272.7492 - val_loss: 269.7698\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 268.7384 - val_loss: 267.0148\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 265.1031 - val_loss: 264.1493\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 261.6842 - val_loss: 261.5077\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 258.3101 - val_loss: 258.9532\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 255.1059 - val_loss: 256.4993\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 252.1828 - val_loss: 254.2834\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 249.1743 - val_loss: 251.9320\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 246.3650 - val_loss: 249.8480\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 243.7273 - val_loss: 247.6310\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 241.0337 - val_loss: 245.5250\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 238.4630 - val_loss: 243.6513\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 236.0487 - val_loss: 241.7703\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 233.7230 - val_loss: 239.8067\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 231.3543 - val_loss: 237.9480\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.0784 - val_loss: 236.0356\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 226.8854 - val_loss: 234.2663\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 224.7262 - val_loss: 232.6058\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 222.6461 - val_loss: 230.7524\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 220.6733 - val_loss: 229.1033\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 218.7076 - val_loss: 227.4653\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 216.8332 - val_loss: 225.9367\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 215.0779 - val_loss: 224.3949\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 213.1826 - val_loss: 222.9189\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 211.5259 - val_loss: 221.5076\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 221.508\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 13ms/step - loss: 1578.4010 - val_loss: 1582.9304\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1564.6862 - val_loss: 1568.4950\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1551.2961 - val_loss: 1554.1431\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1537.9155 - val_loss: 1540.1139\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1524.5435 - val_loss: 1525.2921\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1510.7833 - val_loss: 1510.4447\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1496.9128 - val_loss: 1495.0918\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1482.5170 - val_loss: 1479.2495\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1467.6321 - val_loss: 1463.0236\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1452.0525 - val_loss: 1446.0272\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1436.1594 - val_loss: 1428.1772\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1418.9935 - val_loss: 1409.9084\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1401.3495 - val_loss: 1390.5038\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1382.7477 - val_loss: 1370.1327\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1363.0898 - val_loss: 1349.1610\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1342.4883 - val_loss: 1326.5114\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1320.8994 - val_loss: 1303.0068\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1297.8842 - val_loss: 1278.8088\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1274.0701 - val_loss: 1253.1361\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1249.1968 - val_loss: 1225.9631\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1223.1616 - val_loss: 1198.9010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1196.3163 - val_loss: 1171.0116\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1168.9624 - val_loss: 1142.3229\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1140.5951 - val_loss: 1113.0903\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1112.1444 - val_loss: 1081.8700\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1082.1135 - val_loss: 1052.0525\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1052.6963 - val_loss: 1021.0533\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1022.3647 - val_loss: 990.0414\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 991.5391 - val_loss: 959.2253\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 960.6654 - val_loss: 927.1472\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 929.2258 - val_loss: 895.3419\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 897.6586 - val_loss: 863.9021\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 866.4983 - val_loss: 831.8795\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 835.3616 - val_loss: 800.5480\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 804.3178 - val_loss: 770.1066\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 774.1743 - val_loss: 739.4221\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 744.2407 - val_loss: 710.1515\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 715.2006 - val_loss: 681.2535\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 686.6890 - val_loss: 653.1859\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 659.2773 - val_loss: 626.0157\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 632.5040 - val_loss: 600.0379\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 607.0008 - val_loss: 575.2006\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 582.4168 - val_loss: 550.9709\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 558.3875 - val_loss: 528.4539\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 535.9357 - val_loss: 506.4367\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 514.1876 - val_loss: 485.2359\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 493.4780 - val_loss: 465.2512\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 473.7688 - val_loss: 446.2808\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 454.7808 - val_loss: 429.0748\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 437.3783 - val_loss: 412.1208\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 420.5844 - val_loss: 396.4842\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 404.9154 - val_loss: 381.4477\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 389.7603 - val_loss: 368.0334\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 375.8670 - val_loss: 354.9303\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 362.7124 - val_loss: 342.7779\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 350.5157 - val_loss: 331.4725\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 339.0259 - val_loss: 321.4745\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 328.5384 - val_loss: 311.7641\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 318.5926 - val_loss: 302.8083\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 309.2536 - val_loss: 294.8705\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 300.7019 - val_loss: 287.3051\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 292.5236 - val_loss: 280.4215\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 284.9629 - val_loss: 273.5041\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 277.7682 - val_loss: 267.0810\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 270.9192 - val_loss: 261.3274\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 264.6976 - val_loss: 256.1352\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 258.8707 - val_loss: 250.8684\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 253.2245 - val_loss: 246.1673\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 248.0598 - val_loss: 241.6785\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 243.0789 - val_loss: 237.5491\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 238.4328 - val_loss: 233.5151\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.0716 - val_loss: 229.6918\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 229.8485 - val_loss: 226.0988\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 225.8428 - val_loss: 222.6656\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 222.0773 - val_loss: 219.4119\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 218.4962 - val_loss: 216.2560\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 215.0702 - val_loss: 213.2704\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 211.8895 - val_loss: 210.4408\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 208.7804 - val_loss: 207.7327\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 205.7710 - val_loss: 205.0784\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.8431 - val_loss: 202.5947\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 200.1694 - val_loss: 200.0297\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 197.4749 - val_loss: 197.7441\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 194.9904 - val_loss: 195.3820\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.4898 - val_loss: 193.2254\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 190.1446 - val_loss: 191.0234\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 187.9131 - val_loss: 188.9520\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 185.6470 - val_loss: 186.9624\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 183.6271 - val_loss: 184.9013\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 181.5895 - val_loss: 183.0176\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 179.6218 - val_loss: 181.2157\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 177.7967 - val_loss: 179.3295\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 175.9384 - val_loss: 177.5376\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 174.2924 - val_loss: 175.8078\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 172.4693 - val_loss: 174.0940\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.8201 - val_loss: 172.5732\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 169.2905 - val_loss: 170.7932\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 167.6388 - val_loss: 169.3517\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 166.2324 - val_loss: 167.7528\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 164.7052 - val_loss: 166.4253\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 166.425\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 1528.4694 - val_loss: 1607.4597\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1512.1115 - val_loss: 1589.9169\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1495.6389 - val_loss: 1571.8083\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1478.9728 - val_loss: 1553.2614\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1461.5833 - val_loss: 1535.0471\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1443.7750 - val_loss: 1515.6614\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1425.2533 - val_loss: 1495.6908\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1406.1742 - val_loss: 1475.1055\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1386.2205 - val_loss: 1453.4918\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1365.5935 - val_loss: 1431.0050\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1344.0518 - val_loss: 1408.2327\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1321.9712 - val_loss: 1384.4476\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1299.0085 - val_loss: 1360.1614\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1275.4299 - val_loss: 1335.2578\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1250.9418 - val_loss: 1309.5649\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1225.8025 - val_loss: 1283.1465\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1199.9783 - val_loss: 1256.2048\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1173.4290 - val_loss: 1228.5577\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1146.2130 - val_loss: 1200.4778\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1118.5494 - val_loss: 1172.0889\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1090.5680 - val_loss: 1143.6876\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1062.1182 - val_loss: 1114.3447\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1033.1976 - val_loss: 1085.1045\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1003.9257 - val_loss: 1055.7887\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 974.6163 - val_loss: 1026.2892\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 945.5986 - val_loss: 997.0263\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 916.3847 - val_loss: 968.7583\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 887.6960 - val_loss: 939.8910\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 859.4907 - val_loss: 910.9192\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 831.1382 - val_loss: 883.1184\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 803.2225 - val_loss: 855.7184\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 775.6805 - val_loss: 829.2654\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 748.7671 - val_loss: 803.0255\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 722.6450 - val_loss: 777.1281\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 696.9738 - val_loss: 752.1642\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 672.0777 - val_loss: 727.4472\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 647.4594 - val_loss: 703.7159\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 623.6356 - val_loss: 680.2938\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 600.4192 - val_loss: 657.5652\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 577.7628 - val_loss: 635.9825\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 556.4747 - val_loss: 614.2494\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 535.3716 - val_loss: 593.7844\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 514.9644 - val_loss: 574.1875\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 495.5683 - val_loss: 555.1254\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 477.2374 - val_loss: 535.5068\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 459.0865 - val_loss: 517.1427\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 441.8218 - val_loss: 499.8226\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 425.5349 - val_loss: 482.6991\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 409.8148 - val_loss: 466.1981\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 394.6795 - val_loss: 450.1596\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 380.0416 - val_loss: 435.4627\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 366.5033 - val_loss: 420.3725\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 353.5743 - val_loss: 406.2084\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 341.4617 - val_loss: 392.5358\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 330.1606 - val_loss: 379.6337\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 319.4203 - val_loss: 367.9927\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 309.6572 - val_loss: 357.2180\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 300.8392 - val_loss: 346.5882\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 292.7010 - val_loss: 336.0541\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 284.9188 - val_loss: 326.9217\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 278.0222 - val_loss: 318.4675\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 271.5302 - val_loss: 310.5627\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 265.7356 - val_loss: 302.9222\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 260.1870 - val_loss: 296.5350\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 255.3695 - val_loss: 289.2516\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 250.3408 - val_loss: 283.6576\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 246.1916 - val_loss: 278.5438\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 242.0491 - val_loss: 272.6873\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 238.0957 - val_loss: 267.6370\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 234.4957 - val_loss: 262.8161\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 231.1568 - val_loss: 258.1352\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 228.0106 - val_loss: 254.3360\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 225.0264 - val_loss: 250.1071\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 222.2393 - val_loss: 246.4939\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 219.4154 - val_loss: 242.7827\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 216.7739 - val_loss: 239.0901\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 214.3029 - val_loss: 235.8689\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 211.8666 - val_loss: 232.5987\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 209.4905 - val_loss: 229.1541\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 207.2671 - val_loss: 226.2236\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 205.0098 - val_loss: 223.3554\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.8207 - val_loss: 220.2245\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 200.5933 - val_loss: 217.5665\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 198.4766 - val_loss: 214.6832\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 196.3849 - val_loss: 212.0739\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 194.3872 - val_loss: 209.4357\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 192.4593 - val_loss: 207.0992\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 190.5766 - val_loss: 204.7213\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 188.8232 - val_loss: 202.4028\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 186.9373 - val_loss: 200.0801\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 185.1502 - val_loss: 197.8246\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 183.3321 - val_loss: 195.8589\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 181.4556 - val_loss: 193.3416\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 179.6773 - val_loss: 191.1626\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 177.8949 - val_loss: 189.3167\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 176.1629 - val_loss: 187.1324\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 174.4091 - val_loss: 185.1696\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 172.6501 - val_loss: 182.9489\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 170.9106 - val_loss: 181.0993\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 169.2807 - val_loss: 179.0918\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 179.092\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 1631.1730 - val_loss: 1494.6354\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1615.2009 - val_loss: 1478.9515\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1599.8118 - val_loss: 1463.4644\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1584.5135 - val_loss: 1448.2455\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1569.4663 - val_loss: 1432.7994\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1554.1980 - val_loss: 1417.2737\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1538.6584 - val_loss: 1400.9720\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1522.4967 - val_loss: 1383.9419\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1505.3114 - val_loss: 1366.6288\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1487.6503 - val_loss: 1348.0076\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1469.0562 - val_loss: 1328.3293\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1449.1509 - val_loss: 1308.1627\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1428.6121 - val_loss: 1287.1538\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1407.3210 - val_loss: 1264.6094\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1384.5325 - val_loss: 1242.0043\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1361.5192 - val_loss: 1218.0397\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1337.0457 - val_loss: 1193.8600\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1312.2998 - val_loss: 1168.4720\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1286.5956 - val_loss: 1143.0116\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1260.3890 - val_loss: 1117.1339\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1233.7777 - val_loss: 1090.1349\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1206.2563 - val_loss: 1062.9761\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 1178.2809 - val_loss: 1035.1073\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1149.9786 - val_loss: 1006.7891\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1121.1616 - val_loss: 978.3276\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1092.1179 - val_loss: 950.0196\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1062.8779 - val_loss: 921.1929\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1033.3583 - val_loss: 891.9954\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1003.3317 - val_loss: 863.0505\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 973.2723 - val_loss: 833.9901\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 942.9459 - val_loss: 804.7213\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 912.6483 - val_loss: 775.5949\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 881.9872 - val_loss: 746.7106\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 851.8018 - val_loss: 717.3481\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 820.9307 - val_loss: 688.9972\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 790.8498 - val_loss: 660.3958\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 760.9543 - val_loss: 631.7554\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 731.0704 - val_loss: 604.3736\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 701.9412 - val_loss: 577.7043\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 673.4025 - val_loss: 551.5203\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 645.5811 - val_loss: 526.1992\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 618.4318 - val_loss: 501.6876\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 592.1815 - val_loss: 478.3303\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 567.0757 - val_loss: 455.6451\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 542.7751 - val_loss: 433.8944\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 519.2635 - val_loss: 413.9673\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 497.1542 - val_loss: 394.9841\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 476.1923 - val_loss: 376.6682\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 455.9034 - val_loss: 359.4009\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 436.5956 - val_loss: 343.5800\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 419.0354 - val_loss: 328.4306\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 402.1871 - val_loss: 314.4898\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 386.2412 - val_loss: 301.1779\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 371.4232 - val_loss: 288.8624\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 357.5878 - val_loss: 277.5301\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 344.6122 - val_loss: 267.3809\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 333.1596 - val_loss: 257.6794\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 321.9775 - val_loss: 249.5688\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 312.0706 - val_loss: 241.6541\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 302.7686 - val_loss: 234.5080\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 294.3337 - val_loss: 227.8126\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 286.2166 - val_loss: 221.8620\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 278.9619 - val_loss: 216.4764\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 272.2043 - val_loss: 211.5591\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 266.1208 - val_loss: 207.0061\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 260.2174 - val_loss: 202.9706\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 255.1790 - val_loss: 198.8210\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 249.8790 - val_loss: 195.5759\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 245.3545 - val_loss: 192.3864\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 241.1502 - val_loss: 189.2251\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 237.0933 - val_loss: 186.4953\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 233.2818 - val_loss: 183.8136\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 229.7062 - val_loss: 181.4973\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 226.4516 - val_loss: 179.0321\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 223.2182 - val_loss: 176.9207\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 220.2152 - val_loss: 174.9558\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 217.4104 - val_loss: 173.0174\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 214.4853 - val_loss: 171.2926\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 211.9367 - val_loss: 169.5069\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 209.3761 - val_loss: 167.9225\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 206.9972 - val_loss: 166.3322\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 204.7199 - val_loss: 164.8232\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 202.5372 - val_loss: 163.3894\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 200.4771 - val_loss: 162.0418\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 198.4533 - val_loss: 160.8000\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 196.5287 - val_loss: 159.5663\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 194.6236 - val_loss: 158.2748\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 192.8795 - val_loss: 157.2348\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 191.0903 - val_loss: 156.0586\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 189.4232 - val_loss: 155.0527\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 187.7159 - val_loss: 154.0854\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 186.1772 - val_loss: 153.0432\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 184.7402 - val_loss: 152.2272\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 183.0298 - val_loss: 151.0792\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 181.6698 - val_loss: 150.0947\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 180.1633 - val_loss: 149.3464\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 178.7634 - val_loss: 148.4382\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 177.4492 - val_loss: 147.5485\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 176.0755 - val_loss: 146.7280\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 174.8286 - val_loss: 145.8954\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "The Mean Squared Error (MSE) on the Test set is: 145.895\n",
            "[181.97890612697591, 150.38261880729928, 178.73986915388107, 177.5154462594256, 155.72341984654688, 171.05743651002058, 183.5302814097133, 178.555821484611, 184.1292029097794, 175.746015956944, 149.73669216257824, 152.44480703642557, 165.5413991110702, 173.07646104109034, 158.05637401682586, 180.32710530885544, 157.37158120412144, 163.12471912275538, 151.72157371898484, 166.9023590179721, 140.11921296375547, 182.1776462708228, 182.52178597583423, 171.00910924442593, 164.65861357538628, 185.6565340872103, 146.9405954382275, 184.2428638018426, 143.09811458734083, 147.6112093227989, 169.47017494119373, 166.97008155634455, 166.18232000925883, 178.07171383253808, 163.57687943964422, 180.8446415305842, 185.55321329190747, 179.6713726642515, 191.24307711974708, 199.69302548296156, 170.76583697742677, 161.44218167594263, 147.6286519599035, 168.20762548829398, 173.6661610731859, 160.66291866476777, 170.02757209689543, 221.50762140969337, 166.42527988639404, 179.09177174944818, 145.8954072412113]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean and standard deviation of the MSE scores\n",
        "mean_mse = np.mean(mse_list)\n",
        "std_dev_mse = np.std(mse_list)\n",
        "\n",
        "print(f\"Mean of the MSEs: {mean_mse:.3f}\")\n",
        "print(f\"Standard Deviation of the MSEs: {std_dev_mse:.3f}\")"
      ],
      "metadata": {
        "id": "_Gl0WEtgIOju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cccd376-b794-4a39-9f91-41d31197c4d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the MSEs: 169.614\n",
            "Standard Deviation of the MSEs: 15.499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Increasing the number of epochs in training allows the model more iterations to learn from the data. Each epoch represents a complete pass over the entire dataset, during which the model adjusts its weights based on the error of its predictions. With more epochs, the model has more opportunities to refine these adjustments, minimizing the mean squared error (MSE). This process leads to a better fit as the model iteratively reduces the discrepancy between predicted and actual values, effectively lowering the mean of MSE over time.\n",
        ""
      ],
      "metadata": {
        "id": "v2rIBABHPpOf"
      }
    }
  ]
}